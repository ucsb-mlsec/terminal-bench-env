#!/bin/bash

# Generate a realistic backup archive file (80-90 MB)
# This simulates a recent backup that should be preserved

# Create a temporary directory for generating archive content
TEMP_DIR=$(mktemp -d)
cd "$TEMP_DIR"

# Generate realistic backup data (approximately 250-300 MB uncompressed to get 80-90 MB compressed)
# Simulating typical backup contents: configs, logs, databases, application files

# Create directory structure
mkdir -p etc/nginx
mkdir -p etc/apache2
mkdir -p var/log
mkdir -p opt/application/data
mkdir -p home/users
mkdir -p usr/local/bin

# Generate configuration files
for i in {1..50}; do
    cat > "etc/nginx/site-$i.conf" << 'EOF'
server {
    listen 80;
    server_name example.com;
    root /var/www/html;
    index index.html index.htm index.php;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;
}
EOF
done

# Generate log files with repetitive content
for i in {1..100}; do
    echo "[2024-01-27 $(printf "%02d" $((i % 24))):$(printf "%02d" $((i % 60))):00] INFO Application started successfully" >> var/log/app.log
    echo "[2024-01-27 $(printf "%02d" $((i % 24))):$(printf "%02d" $((i % 60))):05] INFO Processing request from 192.168.1.$((i % 255))" >> var/log/app.log
    echo "[2024-01-27 $(printf "%02d" $((i % 24))):$(printf "%02d" $((i % 60))):10] INFO Database connection established" >> var/log/app.log
done

# Generate database dump simulation
cat > opt/application/data/database.sql << 'EOF'
-- MySQL dump 10.13  Distrib 8.0.32
-- Host: localhost    Database: production
-- Server version	8.0.32

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!50503 SET NAMES utf8mb4 */;

CREATE TABLE users (
  id INT AUTO_INCREMENT PRIMARY KEY,
  username VARCHAR(50) NOT NULL,
  email VARCHAR(100) NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

EOF

# Add bulk data to database dump
for i in {1..5000}; do
    echo "INSERT INTO users (username, email) VALUES ('user$i', 'user$i@example.com');" >> opt/application/data/database.sql
done

# Generate application files
for i in {1..200}; do
    dd if=/dev/urandom of="opt/application/data/file_$i.dat" bs=1024 count=$((500 + RANDOM % 500)) 2>/dev/null
done

# Generate user data
for user in alice bob charlie dave; do
    mkdir -p "home/users/$user"
    dd if=/dev/urandom of="home/users/$user/data.bin" bs=1024 count=$((2000 + RANDOM % 1000)) 2>/dev/null
done

# Create the tar.gz archive
tar czf backup-2024-01-27.tar.gz etc/ var/ opt/ home/ usr/ 2>/dev/null

# Move to final destination
OUTPUT_FILE="${1:-backup-2024-01-27.tar.gz}"
mv backup-2024-01-27.tar.gz "$OUTPUT_FILE"

# Cleanup
cd /
rm -rf "$TEMP_DIR"