import os
import json
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np
from pathlib import Path


class MedicalScanDataset(Dataset):
    """
    Custom PyTorch Dataset for loading medical scan images with robust error handling.
    
    Handles inconsistent dimensions, pixel value ranges, and corrupted files.
    """
    
    def __init__(self, root_dir, target_size=(256, 256)):
        """
        Initialize the dataset.
        
        Args:
            root_dir: Root directory containing subdirectories (benign, malignant, uncertain)
            target_size: Target size for resizing images (height, width)
        """
        self.root_dir = Path(root_dir)
        self.target_size = target_size
        self.class_to_idx = {'benign': 0, 'malignant': 1, 'uncertain': 2}
        
        # Load all valid image paths and labels
        self.samples = []
        self._load_samples()
    
    def _load_samples(self):
        """
        Traverse directory structure and collect all valid image paths.
        Skips corrupted files during initialization.
        """
        for class_name, class_idx in self.class_to_idx.items():
            class_dir = self.root_dir / class_name
            
            if not class_dir.exists():
                continue
            
            # Look for common image extensions
            for ext in ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tif', '*.tiff']:
                for img_path in class_dir.glob(ext):
                    # Try to verify the image can be loaded
                    try:
                        with Image.open(img_path) as img:
                            # Verify it's a valid image by attempting to load it
                            img.verify()
                        
                        # Re-open after verify (verify closes the file)
                        with Image.open(img_path) as img:
                            # Convert to ensure it's readable
                            img.convert('L')
                        
                        self.samples.append((str(img_path), class_idx))
                    except Exception as e:
                        # Skip corrupted files
                        print(f"Skipping corrupted file {img_path}: {e}")
                        continue
    
    def __len__(self):
        """Return the total number of valid samples."""
        return len(self.samples)
    
    def __getitem__(self, idx):
        """
        Load and preprocess an image at the given index.
        
        Args:
            idx: Index of the sample to retrieve
            
        Returns:
            Tuple of (image_tensor, label) where image_tensor has shape (1, 256, 256)
        """
        img_path, label = self.samples[idx]
        
        try:
            # Load image
            img = Image.open(img_path)
            
            # Convert to grayscale
            img = img.convert('L')
            
            # Resize to target size
            img = img.resize(self.target_size, Image.BILINEAR)
            
            # Convert to numpy array
            img_array = np.array(img, dtype=np.float32)
            
            # Normalize to [0, 1] range
            # Handle both 0-255 and already normalized images
            if img_array.max() > 1.0:
                img_array = img_array / 255.0
            
            # Convert to tensor with shape (1, H, W)
            img_tensor = torch.from_numpy(img_array).unsqueeze(0)
            
            return img_tensor, label
            
        except Exception as e:
            # If loading fails at runtime, raise error
            raise RuntimeError(f"Failed to load image at index {idx}: {img_path}. Error: {e}")
    
    def get_class_distribution(self):
        """
        Calculate the distribution of samples across classes.
        
        Returns:
            List of [benign_count, malignant_count, uncertain_count]
        """
        distribution = [0, 0, 0]
        for _, label in self.samples:
            distribution[label] += 1
        return distribution


def create_validation_summary(dataset, output_path='/workspace/validation_summary.json'):
    """
    Create a validation summary of the dataset.
    
    Args:
        dataset: Instance of MedicalScanDataset
        output_path: Path where to save the JSON summary
    """
    # Get total valid images
    total_valid_images = len(dataset)
    
    # Get class distribution
    class_distribution = dataset.get_class_distribution()
    
    # Get image shape from first sample
    if total_valid_images > 0:
        first_image, _ = dataset[0]
        image_shape = list(first_image.shape)
        sample_pixel_mean = round(float(first_image.mean()), 3)
    else:
        image_shape = [1, 256, 256]
        sample_pixel_mean = 0.0
    
    # Create summary dictionary
    summary = {
        "total_valid_images": total_valid_images,
        "class_distribution": class_distribution,
        "image_shape": image_shape,
        "sample_pixel_mean": sample_pixel_mean
    }
    
    # Save to JSON file
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"Validation summary saved to {output_path}")
    print(json.dumps(summary, indent=2))
    
    return summary


if __name__ == "__main__":
    # Create dataset instance
    dataset = MedicalScanDataset(root_dir='/workspace/medical_scans')
    
    # Create validation summary
    create_validation_summary(dataset, output_path='/workspace/validation_summary.json')
    
    # Optional: Test DataLoader compatibility
    if len(dataset) > 0:
        from torch.utils.data import DataLoader
        
        # Test that it works with DataLoader
        dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
        
        # Try to get one batch
        for batch_images, batch_labels in dataloader:
            print(f"\nDataLoader test successful!")
            print(f"Batch images shape: {batch_images.shape}")
            print(f"Batch labels shape: {batch_labels.shape}")
            break