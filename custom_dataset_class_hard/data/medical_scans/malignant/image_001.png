import os
import json
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np


class MedicalScanDataset(Dataset):
    """
    Custom PyTorch Dataset for medical scan images.
    
    Handles grayscale medical images organized in subdirectories by diagnosis category.
    Automatically skips corrupted files and normalizes all images to consistent dimensions.
    """
    
    def __init__(self, root_dir):
        """
        Initialize the dataset.
        
        Args:
            root_dir (str): Root directory containing subdirectories for each class
        """
        self.root_dir = root_dir
        self.categories = ['benign', 'malignant', 'uncertain']
        self.label_map = {'benign': 0, 'malignant': 1, 'uncertain': 2}
        
        self.image_paths = []
        self.labels = []
        
        # Load all valid images
        self._load_dataset()
    
    def _load_dataset(self):
        """
        Scan the directory structure and load all valid images.
        Skips corrupted files without crashing.
        """
        for category in self.categories:
            category_path = os.path.join(self.root_dir, category)
            
            if not os.path.exists(category_path):
                continue
            
            label = self.label_map[category]
            
            # Get all files in the category directory
            try:
                files = os.listdir(category_path)
            except Exception as e:
                print(f"Warning: Could not access directory {category_path}: {e}")
                continue
            
            for filename in files:
                file_path = os.path.join(category_path, filename)
                
                # Skip if not a file
                if not os.path.isfile(file_path):
                    continue
                
                # Try to verify the image can be loaded
                try:
                    img = Image.open(file_path)
                    img.verify()  # Verify it's a valid image
                    # Re-open after verify (verify closes the file)
                    img = Image.open(file_path)
                    img = img.convert('L')  # Ensure grayscale
                    # If we got here, the image is valid
                    self.image_paths.append(file_path)
                    self.labels.append(label)
                except Exception as e:
                    print(f"Warning: Skipping corrupted file {file_path}: {e}")
                    continue
    
    def __len__(self):
        """Return the total number of valid images in the dataset."""
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        """
        Get a single sample from the dataset.
        
        Args:
            idx (int): Index of the sample
            
        Returns:
            tuple: (image_tensor, label) where image_tensor has shape (1, 256, 256)
        """
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        
        # Load and preprocess the image
        try:
            # Load image
            img = Image.open(img_path)
            img = img.convert('L')  # Ensure grayscale
            
            # Resize to 256x256
            img = img.resize((256, 256), Image.BILINEAR)
            
            # Convert to numpy array
            img_array = np.array(img, dtype=np.float32)
            
            # Normalize to [0, 1] range
            # Handle both 0-255 and 0-1 ranges
            if img_array.max() > 1.0:
                img_array = img_array / 255.0
            
            # Convert to tensor with shape (1, 256, 256)
            img_tensor = torch.from_numpy(img_array).unsqueeze(0)
            
            return img_tensor, label
            
        except Exception as e:
            print(f"Error loading image at index {idx} ({img_path}): {e}")
            # Return a zero tensor and the label if loading fails
            return torch.zeros((1, 256, 256), dtype=torch.float32), label
    
    def get_class_distribution(self):
        """
        Get the distribution of samples across classes.
        
        Returns:
            list: [benign_count, malignant_count, uncertain_count]
        """
        distribution = [0, 0, 0]
        for label in self.labels:
            distribution[label] += 1
        return distribution


if __name__ == "__main__":
    # Validation script
    dataset_path = "/workspace/medical_scans"
    
    # Create dataset instance
    print("Loading dataset...")
    dataset = MedicalScanDataset(dataset_path)
    
    # Compute statistics
    total_valid_images = len(dataset)
    class_distribution = dataset.get_class_distribution()
    
    # Get first image to compute sample pixel mean
    if total_valid_images > 0:
        first_image, first_label = dataset[0]
        image_shape = list(first_image.shape)
        sample_pixel_mean = round(float(first_image.mean()), 3)
    else:
        image_shape = [1, 256, 256]
        sample_pixel_mean = 0.0
    
    # Create validation summary
    validation_summary = {
        "total_valid_images": total_valid_images,
        "class_distribution": class_distribution,
        "image_shape": image_shape,
        "sample_pixel_mean": sample_pixel_mean
    }
    
    # Save to JSON
    output_path = "/workspace/validation_summary.json"
    with open(output_path, 'w') as f:
        json.dump(validation_summary, f, indent=2)
    
    print(f"Validation complete!")
    print(f"Total valid images: {total_valid_images}")
    print(f"Class distribution: {class_distribution}")
    print(f"Image shape: {image_shape}")
    print(f"Sample pixel mean: {sample_pixel_mean}")
    print(f"Summary saved to {output_path}")