GPU Process List - System Snapshot
Generated: 2024-01-15 14:32:07
================================================================================

GPU ID | PID   | Process Name              | GPU Memory | User      | Type
-------|-------|---------------------------|------------|-----------|-------------
0      | 12845 | python3                   | 3072MiB    | user1     | Training
0      | 13921 | /opt/cuda/bin/matrixMul   | 512MiB     | user2     | CUDA App
0      | 14203 | python3                   | 4096MiB    | user3     | Inference
0      | 15667 | tensorflow_model_server   | 2048MiB    | mlops     | Serving
0      | 16094 | python3                   | 1536MiB    | user1     | Training
0      | 17238 | /usr/bin/nccl-test        | 896MiB     | user4     | Testing
1      | 18442 | python3                   | 2560MiB    | user2     | Training
1      | 19103 | pytorch_inference         | 1792MiB    | user5     | Inference

Process Details:
- All processes running in EXCLUSIVE_PROCESS compute mode
- No MPS (Multi-Process Service) detected
- Context switching overhead observed during concurrent submissions
- Serial execution detected when multiple processes attempt GPU access

Memory Usage Summary:
--------------------------------------------------------------------------------
GPU 0: 12160MiB / 16384MiB (74.2% utilized)
GPU 1: 4352MiB / 16384MiB (26.6% utilized)

Total Active GPU Processes: 8
Total GPU Memory Allocated: 16512MiB across 2 GPUs

Notes:
- Multiple small processes competing for GPU 0 resources
- Potential candidates for concurrent kernel execution
- Current configuration forces serialization of kernel launches
- No shared context mechanism active