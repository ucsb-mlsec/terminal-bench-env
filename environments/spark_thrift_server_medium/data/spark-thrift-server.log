23/05/15 14:32:41 INFO SparkContext: Running Spark version 3.2.1
23/05/15 14:32:41 INFO ResourceUtils: ==============================================================
23/05/15 14:32:41 INFO ResourceUtils: No custom resources configured for spark.driver.
23/05/15 14:32:41 INFO ResourceUtils: ==============================================================
23/05/15 14:32:41 INFO SparkContext: Submitted application: Thrift JDBC/ODBC Server
23/05/15 14:32:41 INFO SecurityManager: Changing view acls to: spark
23/05/15 14:32:41 INFO SecurityManager: Changing modify acls to: spark
23/05/15 14:32:41 INFO SecurityManager: Changing view acls groups to: 
23/05/15 14:32:41 INFO SecurityManager: Changing modify acls groups to: 
23/05/15 14:32:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
23/05/15 14:32:42 INFO Utils: Successfully started service 'sparkDriver' on port 38471.
23/05/15 14:32:42 INFO SparkEnv: Registering MapOutputTracker
23/05/15 14:32:42 INFO SparkEnv: Registering BlockManagerMaster
23/05/15 14:32:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/05/15 14:32:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/05/15 14:32:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/05/15 14:32:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8f3a4e2c-9b1d-4a3f-8c2e-5d6f7e8a9b0c
23/05/15 14:32:42 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
23/05/15 14:32:42 INFO SparkEnv: Registering OutputCommitCoordinator
23/05/15 14:32:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/05/15 14:32:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://spark-master:4040
23/05/15 14:32:42 INFO SparkContext: Added JAR file:/opt/spark/jars/hive-jdbc-2.3.9.jar at spark://spark-master:38471/jars/hive-jdbc-2.3.9.jar with timestamp 1684157562847
23/05/15 14:32:42 INFO SparkContext: Added JAR file:/opt/spark/jars/hive-service-2.3.9.jar at spark://spark-master:38471/jars/hive-service-2.3.9.jar with timestamp 1684157562848
23/05/15 14:32:43 INFO Executor: Starting executor ID driver on host 192.168.1.100
23/05/15 14:32:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39203.
23/05/15 14:32:43 INFO NettyBlockTransferService: Server created on 192.168.1.100:39203
23/05/15 14:32:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/05/15 14:32:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.100, 39203, None)
23/05/15 14:32:43 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.100:39203 with 366.3 MiB RAM, BlockManagerId(driver, 192.168.1.100, 39203, None)
23/05/15 14:32:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.100, 39203, None)
23/05/15 14:32:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.100, 39203, None)
23/05/15 14:32:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/user/hive/warehouse').
23/05/15 14:32:43 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
23/05/15 14:32:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
23/05/15 14:32:44 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
23/05/15 14:32:44 WARN HiveConf: HiveConf of name hive.metastore.event.db.notification.api.auth does not exist
23/05/15 14:32:44 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
23/05/15 14:32:44 INFO ObjectStore: ObjectStore, initialize called
23/05/15 14:32:45 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
23/05/15 14:32:45 INFO ObjectStore: Initialized ObjectStore
23/05/15 14:32:45 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
23/05/15 14:32:45 INFO SessionState: Created HDFS directory: /tmp/hive/spark/8f3a4e2c-9b1d-4a3f-8c2e-5d6f7e8a9b0c
23/05/15 14:32:45 INFO SessionState: Created local directory: /tmp/spark/8f3a4e2c-9b1d-4a3f-8c2e-5d6f7e8a9b0c
23/05/15 14:32:45 INFO SessionState: Created HDFS directory: /tmp/hive/spark/8f3a4e2c-9b1d-4a3f-8c2e-5d6f7e8a9b0c/_tmp_space.db
23/05/15 14:32:46 INFO HiveMetaStore: Added admin role in metastore
23/05/15 14:32:46 INFO HiveMetaStore: Added public role in metastore
23/05/15 14:32:46 INFO HiveMetaStore: No user is added in admin role, since config is empty
23/05/15 14:32:46 INFO HiveMetaStore: Successfully initialized metastore
23/05/15 14:32:46 INFO HiveMetaStore: Connecting to database: jdbc:derby:;databaseName=/var/lib/spark/metastore_db;create=true
23/05/15 14:32:46 INFO HiveMetaStore: Connected to metastore database successfully
23/05/15 14:32:47 INFO SessionState: Updating database references for schema consolidation
23/05/15 14:32:47 INFO HiveMetaStore: Fetching database list for validation
23/05/15 14:32:47 INFO HiveMetaStore: Found databases: [default, customer_db, test_db, staging_db]
23/05/15 14:32:47 INFO SessionState: Validating primary database configuration
23/05/15 14:32:47 INFO HiveMetaStore: Setting hive.metastore.warehouse.dir to /user/hive/warehouse/customer_db
23/05/15 14:32:47 INFO SessionState: Database warehouse directory set to /user/hive/warehouse/customer_db
23/05/15 14:32:48 INFO MetricsConfig: Loaded properties from hadoop-metrics2-spark.properties
23/05/15 14:32:48 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
23/05/15 14:32:48 INFO MetricsSystemImpl: Spark metrics system started on port 4041
23/05/15 14:32:48 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
23/05/15 14:32:49 INFO HiveThriftServer2: Starting HiveThriftServer2
23/05/15 14:32:49 INFO HiveThriftServer2: Initializing Thrift server configuration
23/05/15 14:32:49 INFO Utils: Successfully started service 'HiveThriftServer2' on port 10000.
23/05/15 14:32:49 INFO HiveThriftServer2: HiveThriftServer2 started with configuration:
23/05/15 14:32:49 INFO HiveThriftServer2:   hive.server2.thrift.port = 10000
23/05/15 14:32:49 INFO HiveThriftServer2:   hive.server2.thrift.bind.host = 0.0.0.0
23/05/15 14:32:49 INFO HiveThriftServer2:   hive.server2.transport.mode = binary
23/05/15 14:32:49 INFO HiveThriftServer2:   hive.server2.authentication = NONE
23/05/15 14:32:50 INFO ThriftBinaryCLIService: Starting ThriftBinaryCLIService on port 10000 with 5...500 worker threads
23/05/15 14:32:50 INFO ThriftCLIService: Initializing Thrift CLI service
23/05/15 14:32:50 INFO ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V10
23/05/15 14:32:50 INFO SessionManager: Operation log root directory: /tmp/spark/operation_logs
23/05/15 14:32:50 INFO SessionManager: Created operation log root directory: /tmp/spark/operation_logs
23/05/15 14:32:51 INFO ThriftBinaryCLIService: ThriftBinaryCLIService listening on 0.0.0.0:10000
23/05/15 14:32:51 INFO HiveThriftServer2: Thrift server has started on port 10000
23/05/15 14:32:51 INFO HiveThriftServer2: You can connect using: beeline -u jdbc:hive2://localhost:10000
23/05/15 14:32:51 INFO SessionState: Current database set to customer_db
23/05/15 14:32:51 INFO CLIService: Session opened, SessionHandle [8f3a4e2c-9b1d-4a3f-8c2e-5d6f7e8a9b0c]
23/05/15 14:32:52 INFO SparkSQLCLIDriver: Spark master: local[*], Application Id: local-1684157571234
23/05/15 14:32:52 INFO HiveThriftServer2: Server is ready to accept connections
23/05/15 14:33:15 INFO ThriftCLIService: Client connection received from 192.168.1.50:52341
23/05/15 14:33:15 INFO SessionManager: Opening session for client connection from 192.168.1.50:52341
23/05/15 14:33:15 INFO CLIService: Opening session: SessionHandle [a1b2c3d4-e5f6-7890-1234-567890abcdef]
23/05/15 14:33:15 INFO SessionState: Initialized session for client 192.168.1.50:52341
23/05/15 14:33:16 INFO SparkExecuteStatementOperation: Running query 'SHOW DATABASES' with id a1b2c3d4-e5f6-7890-1234-567890abcdef_0
23/05/15 14:33:16 INFO CodeGenerator: Code generated in 12.345678 ms
23/05/15 14:33:16 INFO SparkExecuteStatementOperation: Query executed successfully, returned 4 rows
23/05/15 14:33:18 INFO ThriftCLIService: Client connection received from 192.168.1.51:52342
23/05/15 14:33:18 INFO SessionManager: Opening session for client connection from 192.168.1.51:52342
23/05/15 14:33:20 INFO SparkExecuteStatementOperation: Running query 'USE customer_db' with id b2c3d4e5-f6a7-8901-2345-678901bcdef0_0
23/05/15 14:33:20 INFO SessionState: Current database changed to customer_db for session b2c3d4e5-f6a7-8901-2345-678901bcdef0
23/05/15 14:33:22 INFO SparkExecuteStatementOperation: Running query 'SELECT * FROM orders LIMIT 10' with id b2c3d4e5-f6a7-8901-2345-678901bcdef0_1
23/05/15 14:33:22 INFO FileSourceStrategy: Pushed filters: 
23/05/15 14:33:22 INFO FileSourceStrategy: Post-Scan filters: 
23/05/15 14:33:22 INFO CodeGenerator: Code generated in 45.678901 ms
23/05/15 14:33:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.3 KiB, free 366.3 MiB)
23/05/15 14:33:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 366.3 MiB)
23/05/15 14:33:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.100:39203 (size: 5.6 KiB, free: 366.3 MiB)
23/05/15 14:33:23 INFO SparkContext: Created broadcast 0 from broadcast at SparkPlan.scala:78
23/05/15 14:33:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/05/15 14:33:24 INFO SparkExecuteStatementOperation: Query executed successfully, returned 10 rows
23/05/15 14:33:45 INFO ThriftCLIService: Client connection received from 192.168.1.52:52343
23/05/15 14:33:45 INFO SessionManager: Opening session for client connection from 192.168.1.52:52343
23/05/15 14:33:47 INFO SparkExecuteStatementOperation: Running query 'DESCRIBE customer_db.orders' with id c3d4e5f6-a7b8-9012-3456-789012cdef01_0
23/05/15 14:33:47 INFO HiveMetaStore: Fetching table metadata for customer_db.orders
23/05/15 14:33:47 INFO SparkExecuteStatementOperation: Query executed successfully, returned 15 rows
23/05/15 14:34:12 WARN SessionManager: Idle session timeout check: session c3d4e5f6-a7b8-9012-3456-789012cdef01 has been idle for 25 seconds
23/05/15 14:34:30 INFO ThriftCLIService: Client connection received from 192.168.1.53:52344
23/05/15 14:34:30 INFO SessionManager: Opening session for client connection from 192.168.1.53:52344
23/05/15 14:34:32 INFO SparkExecuteStatementOperation: Running query 'SELECT COUNT(*) FROM customer_db.orders WHERE order_date > "2023-01-01"' with id d4e5f6a7-b8c9-0123-4567-890123def012_0
23/05/15 14:34:32 INFO CodeGenerator: Code generated in 23.456789 ms
23/05/15 14:34:32 ERROR TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1, 192.168.1.101, executor 1): java.io.IOException: Connection refused
23/05/15 14:34:32 ERROR TaskSetManager:     at java.net.PlainSocketImpl.socketConnect(Native Method)
23/05/15 14:34:32 ERROR TaskSetManager:     at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
23/05/15 14:34:32 ERROR TaskSetManager:     at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
23/05/15 14:34:33 INFO TaskSetManager: Starting task 0.1 in stage 1.0 (TID 2, 192.168.1.102, executor 2, partition 0, PROCESS_LOCAL, 7823 bytes)
23/05/15 14:34:35 INFO TaskSetManager: Finished task 0.1 in stage 1.0 (TID 2) in 2134 ms on 192.168.1.102 (executor 2) (1/1)
23/05/15 14:34:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/05/15 14:34:35 INFO DAGScheduler: ResultStage 1 (count at SparkPlan.scala:123) finished in 3.456 s
23/05/15 14:34:35 INFO SparkExecuteStatementOperation: Query executed successfully, returned 1 row
23/05/15 14:35:00 INFO SessionManager: Session heartbeat received from 192.168.1.50:52341
23/05/15 14:35:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:35:15 INFO ThriftCLIService: Client connection closed from 192.168.1.52:52343
23/05/15 14:35:15 INFO SessionManager: Closing session: SessionHandle [c3d4e5f6-a7b8-9012-3456-789012cdef01]
23/05/15 14:35:15 INFO CLIService: Session closed, SessionHandle [c3d4e5f6-a7b8-9012-3456-789012cdef01]
23/05/15 14:35:45 INFO SparkExecuteStatementOperation: Running query 'SELECT product_id, SUM(quantity) FROM customer_db.orders GROUP BY product_id' with id b2c3d4e5-f6a7-8901-2345-678901bcdef0_2
23/05/15 14:35:45 INFO CodeGenerator: Code generated in 34.567890 ms
23/05/15 14:35:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 23.4 KiB, free 366.3 MiB)
23/05/15 14:35:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.100:39203 (size: 10.2 KiB, free: 366.3 MiB)
23/05/15 14:35:47 INFO DAGScheduler: Job 2 finished: collect at SparkPlan.scala:234, took 1.234567 s
23/05/15 14:35:47 INFO SparkExecuteStatementOperation: Query executed successfully, returned 127 rows
23/05/15 14:36:00 INFO SessionManager: Session heartbeat received from 192.168.1.50:52341
23/05/15 14:36:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:36:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:36:22 INFO ThriftCLIService: Client connection received from 192.168.1.54:52345
23/05/15 14:36:22 INFO SessionManager: Opening session for client connection from 192.168.1.54:52345
23/05/15 14:36:24 INFO SparkExecuteStatementOperation: Running query 'SHOW TABLES IN test_db' with id e5f6a7b8-c9d0-1234-5678-901234ef0123_0
23/05/15 14:36:24 INFO HiveMetaStore: Fetching table list for database test_db
23/05/15 14:36:24 INFO SparkExecuteStatementOperation: Query executed successfully, returned 23 rows
23/05/15 14:37:00 INFO SessionManager: Session heartbeat received from 192.168.1.50:52341
23/05/15 14:37:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:37:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:37:00 INFO SessionManager: Session heartbeat received from 192.168.1.54:52345
23/05/15 14:37:30 INFO ThriftCLIService: Client connection closed from 192.168.1.50:52341
23/05/15 14:37:30 INFO SessionManager: Closing session: SessionHandle [a1b2c3d4-e5f6-7890-1234-567890abcdef]
23/05/15 14:37:30 INFO CLIService: Session closed, SessionHandle [a1b2c3d4-e5f6-7890-1234-567890abcdef]
23/05/15 14:38:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:38:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:38:00 INFO SessionManager: Session heartbeat received from 192.168.1.54:52345
23/05/15 14:38:15 INFO SparkExecuteStatementOperation: Running query 'SELECT * FROM customer_db.customers WHERE region = "NORTH"' with id b2c3d4e5-f6a7-8901-2345-678901bcdef0_3
23/05/15 14:38:15 INFO FileSourceStrategy: Pushed filters: EqualTo(region,NORTH)
23/05/15 14:38:15 INFO CodeGenerator: Code generated in 18.901234 ms
23/05/15 14:38:16 INFO SparkExecuteStatementOperation: Query executed successfully, returned 456 rows
23/05/15 14:39:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:39:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:39:00 INFO SessionManager: Session heartbeat received from 192.168.1.54:52345
23/05/15 14:39:45 INFO ThriftCLIService: Client connection closed from 192.168.1.54:52345
23/05/15 14:39:45 INFO SessionManager: Closing session: SessionHandle [e5f6a7b8-c9d0-1234-5678-901234ef0123]
23/05/15 14:39:45 INFO CLIService: Session closed, SessionHandle [e5f6a7b8-c9d0-1234-5678-901234ef0123]
23/05/15 14:40:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:40:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:40:30 WARN SessionManager: Idle session timeout check: session d4e5f6a7-b8c9-0123-4567-890123def012 has been idle for 6 minutes
23/05/15 14:41:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:41:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:42:00 INFO SessionManager: Session heartbeat received from 192.168.1.51:52342
23/05/15 14:42:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:42:18 INFO ThriftCLIService: Client connection closed from 192.168.1.51:52342
23/05/15 14:42:18 INFO SessionManager: Closing session: SessionHandle [b2c3d4e5-f6a7-8901-2345-678901bcdef0]
23/05/15 14:42:18 INFO CLIService: Session closed, SessionHandle [b2c3d4e5-f6a7-8901-2345-678901bcdef0]
23/05/15 14:43:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:44:00 INFO SessionManager: Session heartbeat received from 192.168.1.53:52344
23/05/15 14:44:30 INFO ThriftCLIService: Client connection closed from 192.168.1.53:52344
23/05/15 14:44:30 INFO SessionManager: Closing session: SessionHandle [d4e5f6a7-b8c9-0123-4567-890123def012]
23/05/15 14:44:30 INFO CLIService: Session closed, SessionHandle [d4e5f6a7-b8c9-0123-4567-890123def012]
23/05/15 14:45:00 INFO SessionManager: No active sessions remaining
23/05/15 14:45:00 INFO HiveThriftServer2: All client sessions have been closed
23/05/15 14:45:30 INFO HiveThriftServer2: Server has been idle for 30 seconds with no active sessions