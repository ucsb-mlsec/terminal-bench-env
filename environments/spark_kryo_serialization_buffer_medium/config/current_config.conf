# Spark Configuration File
# Application: Distributed Data Processing Pipeline
# Last Updated: 2024-01-15

# Serialization Configuration
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired=false
spark.kryo.referenceTracking=true
spark.kryoserializer.buffer=32k
spark.kryoserializer.buffer.max=64m

# Memory Configuration
spark.executor.memory=4g
spark.driver.memory=2g
spark.executor.memoryOverhead=512m
spark.driver.memoryOverhead=512m
spark.memory.fraction=0.6
spark.memory.storageFraction=0.5

# Execution Configuration
spark.executor.cores=4
spark.executor.instances=10
spark.default.parallelism=80
spark.sql.shuffle.partitions=200

# Network Configuration
spark.network.timeout=300s
spark.executor.heartbeatInterval=30s

# Shuffle Configuration
spark.shuffle.compress=true
spark.shuffle.spill.compress=true
spark.io.compression.codec=snappy

# Dynamic Allocation
spark.dynamicAllocation.enabled=false
spark.shuffle.service.enabled=false

# Application Settings
spark.app.name=DataProcessingPipeline
spark.master=yarn
spark.submit.deployMode=cluster