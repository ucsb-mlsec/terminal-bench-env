# Spark Configuration File
# Current production settings - experiencing issues with data skew and memory pressure

# Application Settings
spark.master=yarn
spark.app.name=ProductionETL
spark.submit.deployMode=cluster

# Memory Configuration
spark.driver.memory=4g
spark.executor.memory=8g
spark.executor.cores=4
spark.executor.instances=20

# Shuffle Configuration - Static partitioning causing issues
spark.sql.shuffle.partitions=200
spark.sql.files.maxPartitionBytes=134217728

# Adaptive Query Execution - Currently DISABLED
spark.sql.adaptive.enabled=false
# spark.sql.adaptive.coalescePartitions.enabled=false
# spark.sql.adaptive.skewJoin.enabled=false

# Join Configuration - Low threshold causing issues
spark.sql.autoBroadcastJoinThreshold=10485760

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max=512m

# Event Logging
spark.eventLog.enabled=true
spark.eventLog.dir=/var/log/spark/events

# Warehouse Configuration
spark.sql.warehouse.dir=/user/spark/warehouse

# Network and Shuffle Settings
spark.network.timeout=300s
spark.shuffle.service.enabled=true
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.minExecutors=5
spark.dynamicAllocation.maxExecutors=50

# Memory Management
spark.memory.fraction=0.6
spark.memory.storageFraction=0.5