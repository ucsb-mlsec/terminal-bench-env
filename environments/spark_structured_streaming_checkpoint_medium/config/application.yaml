spark:
  application:
    name: "DataStreamProcessor"
  streaming:
    checkpoint_location: "/mnt/new_storage/streaming_checkpoints/data_processor"
    trigger_interval: "10 seconds"
  sources:
    kafka:
      bootstrap_servers: "kafka1:9092,kafka2:9092"
      topics: "input_topic"
  sinks:
    output_path: "/data/output"
    checkpoint_dir: "/mnt/new_storage/streaming_checkpoints/kafka_sink"
resources:
  executor_cores: 4
  executor_memory: "8g"