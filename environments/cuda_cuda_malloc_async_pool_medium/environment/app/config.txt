Expected Memory Pool Behavior
================================

The CUDA memory pool in this application is designed to maximize performance
through efficient memory reuse. The following behavior is expected:

1. Freed memory blocks should be retained within the pool for future allocations
   rather than being released back to the operating system.

2. The pool should NOT release memory aggressively. Aggressive release behavior
   causes frequent reallocations which significantly degrade performance.

3. For optimal performance, the release threshold should be set to maximum value
   or effectively disabled to prevent automatic memory release.

4. Expected performance characteristics:
   - Minimal reallocation overhead after initial warmup
   - Fast allocation times due to pool reuse
   - Consistent memory usage patterns

5. Performance degradation symptoms include increased allocation latency and
   frequent cudaMallocAsync calls that cannot be satisfied from the pool cache.