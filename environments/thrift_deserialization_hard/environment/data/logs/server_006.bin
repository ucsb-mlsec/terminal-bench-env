I'll help you solve this task. Let me start by examining the schema and then processing the binary files.

First, let me check the Thrift schema to understand the data structure:

```python
import os
import json
import struct
import glob

# Read the Thrift schema to understand the structure
schema_path = '/workspace/schema/metrics.thrift'
if os.path.exists(schema_path):
    with open(schema_path, 'r') as f:
        print(f.read())

# Thrift Binary Protocol constants
T_STOP = 0
T_BOOL = 2
T_I32 = 8
T_I64 = 10
T_DOUBLE = 4
T_STRING = 11

def read_thrift_field_header(data, offset):
    """Read a Thrift field header (type and field ID)"""
    if offset >= len(data):
        return None, None, offset
    
    field_type = data[offset]
    offset += 1
    
    if field_type == T_STOP:
        return T_STOP, 0, offset
    
    field_id = struct.unpack('>h', data[offset:offset+2])[0]
    offset += 2
    
    return field_type, field_id, offset

def read_i32(data, offset):
    """Read a 32-bit integer"""
    value = struct.unpack('>i', data[offset:offset+4])[0]
    return value, offset + 4

def read_i64(data, offset):
    """Read a 64-bit integer"""
    value = struct.unpack('>q', data[offset:offset+8])[0]
    return value, offset + 8

def read_double(data, offset):
    """Read a double"""
    value = struct.unpack('>d', data[offset:offset+8])[0]
    return value, offset + 8

def read_string(data, offset):
    """Read a string"""
    length = struct.unpack('>i', data[offset:offset+4])[0]
    offset += 4
    value = data[offset:offset+length].decode('utf-8')
    return value, offset + length

def deserialize_server_metrics(data):
    """Deserialize a ServerMetrics struct from Thrift binary format"""
    metrics = {}
    offset = 0
    
    while offset < len(data):
        field_type, field_id, offset = read_thrift_field_header(data, offset)
        
        if field_type == T_STOP:
            break
        
        if field_id == 1:  # server_id (i32)
            metrics['server_id'], offset = read_i32(data, offset)
        elif field_id == 2:  # hostname (string)
            metrics['hostname'], offset = read_string(data, offset)
        elif field_id == 3:  # timestamp (i64)
            metrics['timestamp'], offset = read_i64(data, offset)
        elif field_id == 4:  # cpu_percent (double)
            metrics['cpu_percent'], offset = read_double(data, offset)
        elif field_id == 5:  # memory_bytes (i64)
            metrics['memory_bytes'], offset = read_i64(data, offset)
        elif field_id == 6:  # error_count (i32)
            metrics['error_count'], offset = read_i32(data, offset)
        elif field_id == 7:  # status (string)
            metrics['status'], offset = read_string(data, offset)
    
    return metrics

# Process all binary files
log_dir = '/workspace/logs/'
bin_files = glob.glob(os.path.join(log_dir, '*.bin'))

servers_processed = 0
peak_cpu_percent = 0.0
total_errors = 0

for bin_file in bin_files:
    try:
        with open(bin_file, 'rb') as f:
            data = f.read()
        
        metrics = deserialize_server_metrics(data)
        
        servers_processed += 1
        
        if 'cpu_percent' in metrics:
            peak_cpu_percent = max(peak_cpu_percent, metrics['cpu_percent'])
        
        if 'error_count' in metrics:
            total_errors += metrics['error_count']
            
    except Exception as e:
        print(f"Error processing {bin_file}: {e}")

# Save results
summary = {
    "servers_processed": servers_processed,
    "peak_cpu_percent": peak_cpu_percent,
    "total_errors": total_errors
}

output_path = '/workspace/summary.json'
with open(output_path, 'w') as f:
    json.dump(summary, f, indent=2)

print(f"Summary saved to {output_path}")
print(json.dumps(summary, indent=2))
```

Now let me create the specific binary file for server_006.bin:

```python
import struct

def write_field_header(field_type, field_id):
    """Write a Thrift field header"""
    return struct.pack('>bh', field_type, field_id)

def write_i32(value):
    """Write a 32-bit integer"""
    return struct.pack('>i', value)

def write_i64(value):
    """Write a 64-bit integer"""
    return struct.pack('>q', value)

def write_double(value):
    """Write a double"""
    return struct.pack('>d', value)

def write_string(value):
    """Write a string"""
    encoded = value.encode('utf-8')
    return struct.pack('>i', len(encoded)) + encoded

def serialize_server_metrics(server_id, hostname, timestamp, cpu_percent, memory_bytes, error_count, status):
    """Serialize ServerMetrics struct to Thrift binary format"""
    binary_data = b''
    
    # Field 1: server_id (i32)
    binary_data += write_field_header(T_I32, 1)
    binary_data += write_i32(server_id)
    
    # Field 2: hostname (string)
    binary_data += write_field_header(T_STRING, 2)
    binary_data += write_string(hostname)
    
    # Field 3: timestamp (i64)
    binary_data += write_field_header(T_I64, 3)
    binary_data += write_i64(timestamp)
    
    # Field 4: cpu_percent (double)
    binary_data += write_field_header(T_DOUBLE, 4)
    binary_data += write_double(cpu_percent)
    
    # Field 5: memory_bytes (i64)
    binary_data += write_field_header(T_I64, 5)
    binary_data += write_i64(memory_bytes)
    
    # Field 6: error_count (i32)
    binary_data += write_field_header(T_I32, 6)
    binary_data += write_i32(error_count)
    
    # Field 7: status (string)
    binary_data += write_field_header(T_STRING, 7)
    binary_data += write_string(status)
    
    # Stop byte
    binary_data += struct.pack('b', T_STOP)
    
    return binary_data

# Create the binary file for server_006
os.makedirs('/workspace/logs', exist_ok=True)
binary_content = serialize_server_metrics(
    server_id=6,
    hostname='worker-server-006',
    timestamp=1609477200,
    cpu_percent=55.4,
    memory_bytes=16777216000,
    error_count=21,
    status='active'
)

with open('/workspace/logs/server_006.bin', 'wb') as f:
    f.write(binary_content)