quantization:
  bits: 8
  datatype: 'nf4'
  compute_dtype: 'float16'

lora:
  rank: 256
  alpha: 8
  dropout: 1.5
  target_modules: ['q_proj', 'v_proj']

training:
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 0.0002
  max_steps: 1000