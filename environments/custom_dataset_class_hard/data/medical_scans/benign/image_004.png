import os
import json
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np

class MedicalScanDataset(Dataset):
    """
    Custom PyTorch Dataset for loading medical scan images with quality checks.
    
    Handles:
    - Variable image dimensions (resizes to 256x256)
    - Inconsistent pixel value ranges (normalizes to [0, 1])
    - Corrupted files (skips them)
    - Multi-class classification with directory-based labels
    """
    
    def __init__(self, root_dir):
        """
        Initialize the dataset by scanning the directory structure.
        
        Args:
            root_dir (str): Root directory containing subdirectories for each class
        """
        self.root_dir = root_dir
        self.image_size = 256
        self.classes = ['benign', 'malignant', 'uncertain']
        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}
        
        self.samples = []
        self._load_dataset()
    
    def _load_dataset(self):
        """
        Scan the directory structure and load all valid images.
        Skips corrupted files without crashing.
        """
        for class_name in self.classes:
            class_dir = os.path.join(self.root_dir, class_name)
            
            if not os.path.exists(class_dir):
                continue
            
            label = self.class_to_idx[class_name]
            
            for filename in os.listdir(class_dir):
                if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
                    continue
                
                filepath = os.path.join(class_dir, filename)
                
                # Try to load and validate the image
                try:
                    with Image.open(filepath) as img:
                        # Verify the image can be loaded
                        img.verify()
                    
                    # Re-open for actual use (verify closes the file)
                    with Image.open(filepath) as img:
                        # Convert to grayscale if needed
                        if img.mode != 'L':
                            img = img.convert('L')
                        # Test that we can access pixel data
                        _ = np.array(img)
                    
                    # If we got here, the image is valid
                    self.samples.append((filepath, label))
                    
                except Exception as e:
                    # Skip corrupted files
                    print(f"Skipping corrupted file {filepath}: {str(e)}")
                    continue
    
    def __len__(self):
        """Return the total number of valid samples."""
        return len(self.samples)
    
    def __getitem__(self, idx):
        """
        Get a single sample from the dataset.
        
        Args:
            idx (int): Index of the sample
            
        Returns:
            tuple: (image_tensor, label) where image_tensor has shape (1, 256, 256)
        """
        filepath, label = self.samples[idx]
        
        # Load image
        image = Image.open(filepath)
        
        # Convert to grayscale
        if image.mode != 'L':
            image = image.convert('L')
        
        # Resize to standard dimension
        image = image.resize((self.image_size, self.image_size), Image.BILINEAR)
        
        # Convert to numpy array
        image_array = np.array(image, dtype=np.float32)
        
        # Normalize to [0, 1] range
        # Handle both 0-255 and already normalized images
        if image_array.max() > 1.0:
            image_array = image_array / 255.0
        
        # Convert to tensor with shape (1, 256, 256)
        image_tensor = torch.from_numpy(image_array).unsqueeze(0)
        
        return image_tensor, label
    
    def get_class_distribution(self):
        """
        Get the distribution of samples across classes.
        
        Returns:
            list: Count of samples for each class [benign, malignant, uncertain]
        """
        distribution = [0, 0, 0]
        for _, label in self.samples:
            distribution[label] += 1
        return distribution


if __name__ == "__main__":
    # Validation script
    dataset_path = "/workspace/medical_scans"
    
    # Instantiate the dataset
    dataset = MedicalScanDataset(dataset_path)
    
    # Compute statistics
    total_valid_images = len(dataset)
    class_distribution = dataset.get_class_distribution()
    
    # Get the first sample to check shape and compute pixel mean
    if total_valid_images > 0:
        first_image, first_label = dataset[0]
        image_shape = list(first_image.shape)
        sample_pixel_mean = round(float(first_image.mean()), 3)
    else:
        image_shape = [1, 256, 256]
        sample_pixel_mean = 0.0
    
    # Create summary dictionary
    summary = {
        "total_valid_images": total_valid_images,
        "class_distribution": class_distribution,
        "image_shape": image_shape,
        "sample_pixel_mean": sample_pixel_mean
    }
    
    # Save to JSON file
    output_path = "/workspace/validation_summary.json"
    with open(output_path, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"Validation complete. Summary saved to {output_path}")
    print(f"Total valid images: {total_valid_images}")
    print(f"Class distribution: {class_distribution}")
    print(f"Image shape: {image_shape}")
    print(f"Sample pixel mean: {sample_pixel_mean}")