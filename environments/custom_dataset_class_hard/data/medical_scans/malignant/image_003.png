import os
import json
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np


class MedicalScanDataset(Dataset):
    """
    Custom PyTorch Dataset for loading medical scan images with error handling.
    
    This dataset loads grayscale medical images from a directory structure where
    subdirectories represent different diagnosis categories (benign, malignant, uncertain).
    It handles corrupted files, inconsistent dimensions, and varying pixel value ranges.
    """
    
    def __init__(self, root_dir, target_size=(256, 256)):
        """
        Initialize the dataset by scanning the directory structure.
        
        Args:
            root_dir (str): Path to the root directory containing subdirectories for each class
            target_size (tuple): Target dimensions for resizing images (height, width)
        """
        self.root_dir = root_dir
        self.target_size = target_size
        self.class_to_idx = {'benign': 0, 'malignant': 1, 'uncertain': 2}
        
        # Store valid image paths and their labels
        self.image_paths = []
        self.labels = []
        
        # Scan directory and load all valid images
        self._load_dataset()
    
    def _load_dataset(self):
        """
        Scan the directory structure and collect valid image paths.
        Corrupted files are skipped without crashing.
        """
        for class_name, label in self.class_to_idx.items():
            class_dir = os.path.join(self.root_dir, class_name)
            
            if not os.path.exists(class_dir):
                continue
            
            # Iterate through all files in the class directory
            for filename in os.listdir(class_dir):
                file_path = os.path.join(class_dir, filename)
                
                # Only process files (not subdirectories)
                if not os.path.isfile(file_path):
                    continue
                
                # Try to validate the image file
                if self._is_valid_image(file_path):
                    self.image_paths.append(file_path)
                    self.labels.append(label)
    
    def _is_valid_image(self, file_path):
        """
        Check if an image file can be loaded without errors.
        
        Args:
            file_path (str): Path to the image file
            
        Returns:
            bool: True if the image is valid, False otherwise
        """
        try:
            with Image.open(file_path) as img:
                # Try to load the image data to ensure it's not corrupted
                img.verify()
            # Reopen after verify (verify closes the file)
            with Image.open(file_path) as img:
                img.load()
            return True
        except Exception:
            return False
    
    def __len__(self):
        """Return the total number of valid images in the dataset."""
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        """
        Load and preprocess an image at the given index.
        
        Args:
            idx (int): Index of the image to load
            
        Returns:
            tuple: (image_tensor, label) where image_tensor has shape (1, 256, 256)
        """
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        
        # Load image
        image = Image.open(img_path)
        
        # Convert to grayscale if needed
        if image.mode != 'L':
            image = image.convert('L')
        
        # Resize to target dimensions
        image = image.resize(self.target_size, Image.BILINEAR)
        
        # Convert to numpy array
        img_array = np.array(image, dtype=np.float32)
        
        # Normalize to [0, 1] range
        # Handle both 0-255 and already normalized images
        if img_array.max() > 1.0:
            img_array = img_array / 255.0
        
        # Convert to PyTorch tensor with shape (1, H, W)
        img_tensor = torch.from_numpy(img_array).unsqueeze(0)
        
        return img_tensor, label
    
    def get_class_distribution(self):
        """
        Get the distribution of samples across classes.
        
        Returns:
            list: Count of samples for each class [benign, malignant, uncertain]
        """
        distribution = [0, 0, 0]
        for label in self.labels:
            distribution[label] += 1
        return distribution


if __name__ == "__main__":
    # Create dataset instance
    dataset = MedicalScanDataset('/workspace/medical_scans/')
    
    # Prepare validation summary
    summary = {}
    
    # Total valid images
    summary['total_valid_images'] = len(dataset)
    
    # Class distribution
    summary['class_distribution'] = dataset.get_class_distribution()
    
    # Image shape
    if len(dataset) > 0:
        sample_image, _ = dataset[0]
        summary['image_shape'] = list(sample_image.shape)
        
        # Sample pixel mean (first image)
        sample_pixel_mean = float(sample_image.mean())
        summary['sample_pixel_mean'] = round(sample_pixel_mean, 3)
    else:
        summary['image_shape'] = [1, 256, 256]
        summary['sample_pixel_mean'] = 0.0
    
    # Save validation summary to JSON
    with open('/workspace/validation_summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"Dataset validation complete!")
    print(f"Total valid images: {summary['total_valid_images']}")
    print(f"Class distribution: {summary['class_distribution']}")
    print(f"Image shape: {summary['image_shape']}")
    print(f"Sample pixel mean: {summary['sample_pixel_mean']}")