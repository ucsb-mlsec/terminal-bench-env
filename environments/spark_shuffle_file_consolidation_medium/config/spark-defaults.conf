# Spark Configuration File
# This file contains default properties for the Spark application

# Application Properties
spark.app.name=DataProcessingApp
spark.master=yarn
spark.submit.deployMode=cluster

# Memory Configuration
spark.executor.memory=4g
spark.driver.memory=2g
spark.executor.memoryOverhead=512m
spark.driver.memoryOverhead=512m

# CPU Configuration
spark.executor.cores=4
spark.driver.cores=2
spark.default.parallelism=800

# Serialization
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired=false

# Shuffle Configuration - SUBOPTIMAL SETTINGS
spark.sql.shuffle.partitions=2000
spark.shuffle.file.buffer=32k
spark.reducer.maxSizeInFlight=48m
spark.shuffle.sort.bypassMergeThreshold=200
spark.sql.adaptive.enabled=false
spark.sql.adaptive.coalescePartitions.enabled=false

# Network Configuration
spark.network.timeout=300s
spark.executor.heartbeatInterval=30s

# Storage Configuration
spark.storage.level=MEMORY_AND_DISK_SER
spark.rdd.compress=true

# Logging
spark.eventLog.enabled=true
spark.eventLog.dir=/opt/spark/logs/events

# Dynamic Allocation
spark.dynamicAllocation.enabled=false
spark.shuffle.service.enabled=true

# Compression
spark.io.compression.codec=snappy
spark.io.compression.lz4.blockSize=128k