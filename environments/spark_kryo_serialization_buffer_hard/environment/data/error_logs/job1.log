2024-01-15 10:23:41 INFO SparkContext: Running Spark version 3.4.1
2024-01-15 10:23:41 INFO ResourceUtils: ==============================================================
2024-01-15 10:23:41 INFO ResourceUtils: No custom resources configured for spark.driver.
2024-01-15 10:23:41 INFO ResourceUtils: ==============================================================
2024-01-15 10:23:41 INFO SparkContext: Submitted application: DataAggregationJob
2024-01-15 10:23:42 INFO SecurityManager: Changing view acls to: sparkuser
2024-01-15 10:23:42 INFO SecurityManager: Changing modify acls to: sparkuser
2024-01-15 10:23:42 INFO SecurityManager: Changing view acls groups to: 
2024-01-15 10:23:42 INFO SecurityManager: Changing modify acls groups to: 
2024-01-15 10:23:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sparkuser); groups with view permissions: Set(); users  with modify permissions: Set(sparkuser); groups with modify permissions: Set()
2024-01-15 10:23:43 INFO Utils: Successfully started service 'sparkDriver' on port 42157.
2024-01-15 10:23:43 INFO SparkEnv: Registering MapOutputTracker
2024-01-15 10:23:43 INFO SparkEnv: Registering BlockManagerMaster
2024-01-15 10:23:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-01-15 10:23:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2024-01-15 10:23:44 INFO SparkEnv: Registering OutputCommitCoordinator
2024-01-15 10:23:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2024-01-15 10:23:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2024-01-15 10:23:44 INFO SparkContext: Added JAR file:/opt/spark/jars/app.jar at spark://spark-master:7077/jars/app.jar with timestamp 1705315424123
2024-01-15 10:23:45 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-01-15 10:23:45 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2024-01-15 10:23:45 INFO SharedState: Warehouse path is 'file:/opt/spark/work/spark-warehouse'.
2024-01-15 10:23:46 INFO DAGScheduler: Got job 0 (collect at DataAggregationJob.scala:45) with 8 output partitions
2024-01-15 10:23:46 INFO DAGScheduler: Final stage: ResultStage 0 (collect at DataAggregationJob.scala:45)
2024-01-15 10:23:46 INFO DAGScheduler: Parents of final stage: List()
2024-01-15 10:23:46 INFO DAGScheduler: Missing parents: List()
2024-01-15 10:23:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at map at DataAggregationJob.scala:42), which has no missing parents
2024-01-15 10:23:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 23.5 KB, free 366.3 MB)
2024-01-15 10:23:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.2 KB, free 366.3 MB)
2024-01-15 10:23:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-master:42157 (size: 13.2 KB, free: 366.3 MB)
2024-01-15 10:23:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
2024-01-15 10:23:46 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at map at DataAggregationJob.scala:42) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2024-01-15 10:23:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks resource profile 0
2024-01-15 10:23:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.1.101, executor 1, partition 0, PROCESS_LOCAL, 4752 bytes) 
2024-01-15 10:23:46 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.1.102, executor 2, partition 1, PROCESS_LOCAL, 4752 bytes)
2024-01-15 10:23:46 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (192.168.1.103, executor 3, partition 2, PROCESS_LOCAL, 4752 bytes)
2024-01-15 10:23:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.101:38471 (size: 13.2 KB, free: 366.3 MB)
2024-01-15 10:23:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.102:38471 (size: 13.2 KB, free: 366.3 MB)
2024-01-15 10:23:48 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (192.168.1.101 executor 1): org.apache.spark.SparkException: Task failed while writing rows
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:326)
	at org.apache.spark.scheduler.Task.run(Task.scala:136)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)
Caused by: org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 64, required: 87342
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:366)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:428)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
Caused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 64, required: 87342
Serialization trace:
aggregatedData (com.example.spark.models.AggregatedRecord)
	at com.esotericsoftware.kryo.io.Output.require(Output.java:167)
	at com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:251)
	at com.esotericsoftware.kryo.io.Output.writeString(Output.java:326)
	at org.apache.spark.serializer.KryoSerializer.serialize(KryoSerializer.scala:363)
2024-01-15 10:23:48 INFO TaskSetManager: Starting task 0.1 in stage 0.0 (TID 3) (192.168.1.104, executor 4, partition 0, PROCESS_LOCAL, 4752 bytes)
2024-01-15 10:23:49 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
2024-01-15 10:23:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2024-01-15 10:23:49 INFO TaskSchedulerImpl: Cancelling stage 0
2024-01-15 10:23:49 INFO DAGScheduler: ResultStage 0 (collect at DataAggregationJob.scala:45) failed in 2.831 s due to Stage aborted: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0) (192.168.1.101 executor 1): org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 64, required: 87342
2024-01-15 10:23:49 INFO DAGScheduler: Job 0 failed: collect at DataAggregationJob.scala:45, took 3.142587 s
2024-01-15 10:23:49 ERROR ApplicationMaster: User class threw exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)