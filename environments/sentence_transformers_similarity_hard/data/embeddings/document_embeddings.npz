import numpy as np
import os

# Create directory if it doesn't exist
os.makedirs('/workspace/embeddings', exist_ok=True)

# Set random seed for reproducibility
np.random.seed(42)

# Generate 80 document IDs
doc_ids = np.array([f'doc_{i:03d}' for i in range(1, 81)], dtype=object)

# Generate realistic sentence transformer embeddings
# Strategy: Create embeddings that form clusters to simulate documents with similar topics

n_docs = 80
embedding_dim = 384
n_clusters = 8  # Create 8 topic clusters

# Generate cluster centers
cluster_centers = np.random.randn(n_clusters, embedding_dim).astype(np.float32)
# Normalize cluster centers
cluster_centers = cluster_centers / np.linalg.norm(cluster_centers, axis=1, keepdims=True)

# Assign documents to clusters
docs_per_cluster = n_docs // n_clusters
cluster_assignments = np.repeat(np.arange(n_clusters), docs_per_cluster)
# Handle remaining documents
remaining = n_docs - len(cluster_assignments)
if remaining > 0:
    cluster_assignments = np.concatenate([cluster_assignments, np.arange(remaining)])

# Shuffle cluster assignments
np.random.shuffle(cluster_assignments)

# Generate embeddings by adding noise to cluster centers
embeddings = np.zeros((n_docs, embedding_dim), dtype=np.float32)

for i in range(n_docs):
    cluster_id = cluster_assignments[i]
    # Start with cluster center
    embedding = cluster_centers[cluster_id].copy()
    # Add Gaussian noise (smaller noise = more similar within cluster)
    noise = np.random.randn(embedding_dim).astype(np.float32) * 0.3
    embedding = embedding + noise
    # Normalize to unit length (typical for sentence transformers)
    embedding = embedding / np.linalg.norm(embedding)
    embeddings[i] = embedding

# Ensure embeddings are properly normalized and realistic
# Add small variations to make them more realistic
for i in range(n_docs):
    # Slight adjustment to ensure values are in realistic range
    embeddings[i] = embeddings[i] / (np.linalg.norm(embeddings[i]) + 1e-8)

# Verify the embeddings have reasonable properties
# Check that cosine similarities are in expected range
sample_sims = []
for i in range(min(10, n_docs)):
    for j in range(i+1, min(10, n_docs)):
        sim = np.dot(embeddings[i], embeddings[j])
        sample_sims.append(sim)

# Save to npz file
np.savez('/workspace/embeddings/document_embeddings.npz', 
         embeddings=embeddings, 
         doc_ids=doc_ids)

print(f"Generated embeddings with shape: {embeddings.shape}")
print(f"Generated {len(doc_ids)} document IDs")
print(f"Sample similarities range: {min(sample_sims):.3f} to {max(sample_sims):.3f}")
print(f"Embedding value range: {embeddings.min():.3f} to {embeddings.max():.3f}")
print(f"File saved to: /workspace/embeddings/document_embeddings.npz")