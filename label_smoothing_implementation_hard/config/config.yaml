training:
  batch_size: 64
  epochs: 100
  learning_rate: 0.001
  optimizer: 'adam'

model:
  num_classes: 10
  architecture: 'custom_cnn'
  hidden_layers: [128, 64, 32]

loss:
  type: 'cross_entropy'

data:
  train_path: '/workspace/training/data/train.npy'
  val_path: '/workspace/training/data/val.npy'
  num_workers: 4

logging:
  log_interval: 10
  save_checkpoints: true
  checkpoint_dir: '/workspace/training/checkpoints'