Migration Notes - GPU Account Configurations
Last updated: 2024-01-15 by jdavis

So we're finally moving to the new SLURM cluster. Need to track all the GPU allocations carefully b/c the finance dept is breathing down our necks about compute costs.

The astronomy account has gpu limit of 8 which they've been using for their simulation work. Prof. Chen requested this back in Sept and we approved it. They're running some massive cosmology sims that need the parallel processing.

TODO: Verify robotics dept GPU allocation before migration
TODO: Check if imaging account still needs 6 GPUs or if we can reduce
TODO: Review particle_physics limits - they keep going over

Set robotics to use 4 GPUs max per the agreement with Dept Head Martinez. This was decided in the Nov 2023 budget meeting. They mainly use it for ML training on robot nav systems.

The ceramics group surprised me - they actually need GPUs for molecular dynamics simulations of ceramic materials at high temps. Account: ceramics - TRES: gres/gpu=3 (approved 2023-12-01)

biochemistry team has been allocated 12 GPUs total. This is split across their three main research groups. Dr. Patel's group uses most of it for protein folding work. Big project funded by NIH so they have the budget for it.

NOTE: The old graphics_lab account had GPU limits but that dept merged with imaging last semester so that account should be deprecated now. Don't migrate graphics_lab configs!!!

Rendering account was set up in December for the new visualization center. Account: rendering - TRES: gres/gpu=10. They're doing architectural visualization and some movie rendering for the film studies program (weird but whatever, they paid for it).

particle_physics keeps submitting jobs that hit their limits. Current allocation is gres/gpu=16 but they want more. Told them to wait until after migration to request increase. Their ATLAS collaboration work is GPU-intensive apparently.

Jan 12 meeting notes: imaging account confirmed needs to stay at 6 GPUs. They're doing medical imaging processing and the radiomics research is picking up.

The chemistry dept asked about GPU access but we told them to use the general pool for now unless they have specific needs. No dedicated allocation yet for them.

DEPRECATED: testaccount_gpu was just for testing the old scheduler - DO NOT MIGRATE

Also talked to facilities about power requirements. The GPUs draw a ton of power and we might need electrical upgrades in the server room. Mike from facilities said he'd look into it.

engineering_general partition has some GPU nodes but no per-account limits. Users share from common pool there.

Accounting export from old system showed materials_science account with GPU config but I think that was never actually activated? Need to check with Sarah if they ever used it.

TODO: Document all GPU account limits in the new wiki once migration complete

The neuroscience group just got a new grant and wants GPU access. Will set them up after migration. Tentatively planning Account: neuroscience with maybe 5-6 GPUs pending budget approval.

Random note: particle_physics account owner is Prof. Yamamoto - contact: yamamoto@university.edu if issues during migration

Someone set up an ml_research account last year with 8 GPU limit for the machine learning lab. That's still active and should be migrated.

Reminder to self: verify all gres/gpu TRES configs are using correct syntax in new SLURM version. Format changed slightly.