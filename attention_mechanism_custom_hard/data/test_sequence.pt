import torch
import torch.nn as nn

# Generate test data that will cause numerical instability in buggy implementations
torch.manual_seed(42)

# Create tensors with specific properties to trigger overflow
batch_size = 1
seq_length = 256
dimension = 64

# Query: normal distribution with std=0.5, some larger values
query = torch.randn(batch_size, seq_length, dimension) * 0.5
# Add some larger values to specific positions to create extreme dot products
query[0, :20, :] *= 4.0  # Make first 20 queries stronger

# Key: correlated with query to create high attention scores
# Use similar patterns to query to get large dot products
key = torch.randn(batch_size, seq_length, dimension) * 0.5
# Make keys correlated with queries for first 20 positions
key[0, :20, :] = query[0, :20, :] * 0.8 + torch.randn(20, dimension) * 0.1
# Add some additional large values
key[0, 10:30, :] *= 3.0

# Value: normal distribution with std=0.3
value = torch.randn(batch_size, seq_length, dimension) * 0.3

# Verify that this will cause issues with naive implementation
# Compute scaled dot product to check
scale = dimension ** 0.5
scores = torch.matmul(query, key.transpose(-2, -1)) / scale

# Check that we have some very large scores that will overflow in exp()
max_score = scores.max().item()
min_score = scores.min().item()

print(f"Max score before softmax: {max_score}")
print(f"Min score before softmax: {min_score}")
print(f"Score range: {max_score - min_score}")

# Verify exp overflow will occur
if max_score > 50:
    print(f"WARNING: Max score {max_score} will likely cause exp() overflow")

# Create the dictionary to save
test_data = {
    'query': query,
    'key': key,
    'value': value
}

# Save the test data
torch.save(test_data, '/workspace/test_sequence.pt')

print("Test sequence data generated successfully")
print(f"Query shape: {query.shape}")
print(f"Key shape: {key.shape}")
print(f"Value shape: {value.shape}")