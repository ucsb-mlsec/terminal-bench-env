[2024-01-15 09:23:41] Job job_001: FAILED - sbatch: error: Batch job submission failed: Requested node configuration is not available
Job requested --gres=gpu:v100:8 on partition gpu-standard
SLURM Error: Invalid generic resource (gres) specification
Reason: Requested 8 GPUs exceeds partition limit of 4 GPUs per job on gpu-standard
ErrorCode: 2067 - ESLURM_INVALID_GRES

[2024-01-15 10:47:18] Job job_002: FAILED - sbatch: error: Batch job submission failed: Invalid generic resource (gres) specification
Job requested --gres=gpu:a100:2 --partition=gpu-standard
SLURM Error: Requested GRES gpu:a100 not configured on partition gpu-standard
Reason: GPU type 'a100' is not available in partition gpu-standard. Available types: v100, rtx3090
ErrorCode: 2067 - ESLURM_INVALID_GRES

[2024-01-15 11:12:55] Job job_003: FAILED - sbatch: error: Invalid generic resource (gres) specification
Job requested --gres=gpu:tesla:4 --partition=gpu-compute
SLURM Error: gres/gpu type tesla not configured in slurm.conf
Reason: GPU type 'tesla' does not exist in cluster configuration
ErrorCode: 2067 - ESLURM_INVALID_GRES

[2024-01-15 13:28:33] Job job_004: FAILED - sbatch: error: invalid GRES job specification
Job requested --gres=gpu=v100:2 --partition=gpu-standard
SLURM Error: Parse error in GRES specification
Reason: Incorrect GRES syntax. Use colon separator 'gpu:v100:2' not equals sign 'gpu=v100:2'
ErrorCode: 2010 - ESLURM_INVALID_GRES_TYPE

[2024-01-15 14:51:09] Job job_005: FAILED - sbatch: error: Batch job submission failed: Requested node configuration is not available
Job requested --mem=512G --gres=gpu:v100:2 --partition=gpu-standard
SLURM Error: Memory specification exceeds available memory
Reason: Requested 512GB memory exceeds maximum available 256GB per node on gpu-standard partition
ErrorCode: 2080 - ESLURM_REQUESTED_NODE_CONFIG_UNAVAILABLE

[2024-01-15 15:39:27] Job job_006: FAILED - sbatch: error: Batch job submission failed: Requested node configuration is not available
Job requested --gres=gpu:a40:4 --partition=gpu-compute
SLURM Error: Requested resource configuration not available
Reason: Requested 4 GPUs of type a40 but gpu-compute partition nodes have maximum 2 GPUs per node
ErrorCode: 2080 - ESLURM_REQUESTED_NODE_CONFIG_UNAVAILABLE

[2024-01-15 16:14:52] Job job_007: FAILED - sbatch: error: Batch job submission failed: Job violates accounting/QOS policy
Job requested --time=8-00:00:00 --gres=gpu:v100:1 --partition=gpu-standard
SLURM Error: TimeLimit exceeds partition MaxTime
Reason: Requested time limit 8 days exceeds partition gpu-standard MaxTime of 3 days (72 hours)
ErrorCode: 2098 - ESLURM_ACCOUNTING_POLICY

[2024-01-15 17:03:18] Job job_008: FAILED - sbatch: error: Batch job submission failed: Invalid generic resource (gres) specification
Job requested --gres=gpu:3 --partition=gpu-compute
SLURM Error: GRES type not specified in multi-type GPU environment
Reason: Partition gpu-compute has multiple GPU types (a100, a40). Must specify type explicitly: gpu:TYPE:count
ErrorCode: 2067 - ESLURM_INVALID_GRES

[2024-01-15 18:22:44] Job job_009: FAILED - sbatch: error: Batch job submission failed: Requested node configuration is not available
Job requested --mem-per-gpu=96G --gres=gpu:rtx3090:4 --partition=gpu-standard
SLURM Error: Memory per GPU exceeds available memory
Reason: Requested 96GB per GPU (384GB total for 4 GPUs) exceeds node memory capacity of 256GB on gpu-standard
ErrorCode: 2080 - ESLURM_REQUESTED_NODE_CONFIG_UNAVAILABLE

[2024-01-15 19:45:31] Job job_010: FAILED - sbatch: error: Batch job submission failed: Invalid account or account/partition combination specified
Job requested --gres=gpu:v100:2 --partition=gpu-high-mem --qos=express
SLURM Error: QOS express not available for partition gpu-high-mem
Reason: Quality of Service 'express' is not configured for partition gpu-high-mem. Available QOS: normal, long
ErrorCode: 2045 - ESLURM_INVALID_QOS