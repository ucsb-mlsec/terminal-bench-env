2024-01-18 16:22:15 INFO SparkContext: Running Spark version 3.4.1
2024-01-18 16:22:15 INFO ResourceUtils: ==============================================================
2024-01-18 16:22:15 INFO ResourceUtils: No custom resources configured for spark.driver.
2024-01-18 16:22:15 INFO ResourceUtils: ==============================================================
2024-01-18 16:22:16 INFO SparkContext: Submitted application: DataProcessingJob4
2024-01-18 16:22:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-01-18 16:22:17 INFO SecurityManager: Changing view acls to: spark
2024-01-18 16:22:17 INFO SecurityManager: Changing modify acls to: spark
2024-01-18 16:22:17 INFO SecurityManager: Changing view acls groups to: 
2024-01-18 16:22:17 INFO SecurityManager: Changing modify acls groups to: 
2024-01-18 16:22:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
2024-01-18 16:22:18 INFO Utils: Successfully started service 'sparkDriver' on port 42517.
2024-01-18 16:22:19 INFO SparkEnv: Registering MapOutputTracker
2024-01-18 16:22:19 INFO SparkEnv: Registering BlockManagerMaster
2024-01-18 16:22:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-01-18 16:22:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2024-01-18 16:22:20 INFO SparkEnv: Registering OutputCommitCoordinator
2024-01-18 16:22:21 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
2024-01-18 16:22:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2024-01-18 16:22:22 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://master-node:7077...
2024-01-18 16:22:23 INFO TransportClientFactory: Successfully created connection to master-node/192.168.1.10:7077 after 89 ms (0 ms spent in bootstraps)
2024-01-18 16:22:23 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240118162223-0047
2024-01-18 16:22:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240118162223-0047/0 on worker-20240115142803-192.168.1.20-35841 (192.168.1.20:35841) with 2 core(s)
2024-01-18 16:22:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20240118162223-0047/0 on hostPort 192.168.1.20:35841 with 2 core(s), 4.0 GiB RAM
2024-01-18 16:22:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240118162223-0047/1 on worker-20240115142811-192.168.1.21-40257 (192.168.1.21:40257) with 2 core(s)
2024-01-18 16:22:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20240118162223-0047/1 on hostPort 192.168.1.21:40257 with 2 core(s), 4.0 GiB RAM
2024-01-18 16:22:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-driver, 42517, None)
2024-01-18 16:22:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-driver, 42517, None)
2024-01-18 16:22:26 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2024-01-18 16:22:27 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2024-01-18 16:22:27 INFO SharedState: Warehouse path is 'file:/workspace/spark-warehouse'.
2024-01-18 16:22:29 INFO DAGScheduler: Got job 0 (reduce at DataProcessingJob4.scala:87) with 200 output partitions
2024-01-18 16:22:29 INFO DAGScheduler: Final stage: ResultStage 0 (reduce at DataProcessingJob4.scala:87)
2024-01-18 16:22:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
2024-01-18 16:22:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
2024-01-18 16:22:30 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at map at DataProcessingJob4.scala:72), which has no missing parents
2024-01-18 16:22:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 312.4 KiB, free 366.2 MiB)
2024-01-18 16:22:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 89.7 KiB, free 366.1 MiB)
2024-01-18 16:22:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-driver:42517 (size: 89.7 KiB, free: 366.2 MiB)
2024-01-18 16:22:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2024-01-18 16:22:33 INFO DAGScheduler: Submitting 200 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at map at DataProcessingJob4.scala:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2024-01-18 16:22:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 200 tasks resource profile 0
2024-01-18 16:22:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 0) (192.168.1.20, executor 0, partition 0, PROCESS_LOCAL, 4829 bytes) 
2024-01-18 16:22:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 1) (192.168.1.21, executor 1, partition 1, PROCESS_LOCAL, 4829 bytes)
2024-01-18 16:22:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.20:41693 (size: 89.7 KiB, free: 4.0 GiB)
2024-01-18 16:22:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.21:38547 (size: 89.7 KiB, free: 4.0 GiB)
2024-01-18 16:22:41 ERROR TaskSchedulerImpl: Lost executor 0 on 192.168.1.20: Unable to serialize shuffle data
2024-01-18 16:22:41 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 0)
org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 432817264. To avoid this, increase spark.kryos.serializer.buffer.max value.
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:362)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:549)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:552)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 0, required: 432817264
	at com.esotericsoftware.kryo.io.Output.require(Output.java:167)
	at com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:251)
	at com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:229)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:47)
	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:40)
	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:539)
	at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:358)
	... 6 more
2024-01-18 16:22:41 ERROR KryoSerializer: Attempted to serialize object of size 432817264 bytes, which exceeds the maximum buffer size of 67108864 bytes. Current buffer can only hold 0 bytes.
2024-01-18 16:22:41 ERROR KryoSerializer: Buffer expansion failed. Cannot allocate buffer beyond maximum size of 67108864 bytes (configured by spark.kryos.serializer.buffer.max)
2024-01-18 16:22:41 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 0) (192.168.1.20 executor 0): org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 432817264. To avoid this, increase spark.kryos.serializer.buffer.max value.
2024-01-18 16:22:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2024-01-18 16:22:42 INFO DAGScheduler: ShuffleMapStage 1 (map at DataProcessingJob4.scala:72) failed in 11.873 s due to Stage failed because a task failed: Kryo serialization failed: Buffer overflow
2024-01-18 16:22:42 ERROR TaskSchedulerImpl: Task 0 in stage 1.0 failed 1 times; aborting job
2024-01-18 16:22:42 INFO DAGScheduler: Job 0 failed: reduce at DataProcessingJob4.scala:87, took 13.246815 s
2024-01-18 16:22:42 ERROR ApplicationMaster: User application exited with status 1
2024-01-18 16:22:43 INFO SparkContext: Invoking stop() from shutdown hook
2024-01-18 16:22:43 INFO SparkUI: Stopped Spark web UI at http://spark-driver:4040
2024-01-18 16:22:43 INFO StandaloneSchedulerBackend: Shutting down all executors
2024-01-18 16:22:43 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
2024-01-18 16:22:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2024-01-18 16:22:43 INFO MemoryStore: MemoryStore cleared
2024-01-18 16:22:43 INFO BlockManager: BlockManager stopped
2024-01-18 16:22:43 INFO BlockManagerMaster: BlockManagerMaster stopped
2024-01-18 16:22:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2024-01-18 16:22:43 INFO SparkContext: Successfully stopped SparkContext
2024-01-18 16:22:43 INFO ShutdownHookManager: Shutdown hook called