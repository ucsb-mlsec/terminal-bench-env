# Spark Configuration File
# Default configuration settings for the Spark application

spark.executor.memory=4g
spark.driver.memory=2g

# Adaptive query execution
spark.sql.adaptive.enabled=true

# Arrow-based columnar data transfer
spark.sql.execution.arrow.pyspark.enabled=true

# spark.executor.cores=4
# spark.sql.shuffle.partitions=200

spark.network.timeout=300s