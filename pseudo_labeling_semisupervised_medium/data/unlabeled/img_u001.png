I'll create a solution that generates the required images and implements a semi-supervised learning approach to improve classification accuracy.

```python
#!/usr/bin/env python3
import os
import numpy as np
from PIL import Image, ImageDraw
import random
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.semi_supervised import LabelPropagation
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
np.random.seed(42)
random.seed(42)

# Create directories
os.makedirs('/data/labeled/electronics', exist_ok=True)
os.makedirs('/data/labeled/clothing', exist_ok=True)
os.makedirs('/data/labeled/furniture', exist_ok=True)
os.makedirs('/data/unlabeled', exist_ok=True)
os.makedirs('/data/test', exist_ok=True)
os.makedirs('/data/test/electronics', exist_ok=True)
os.makedirs('/data/test/clothing', exist_ok=True)
os.makedirs('/data/test/furniture', exist_ok=True)
os.makedirs('/solution', exist_ok=True)

def create_electronics_image(seed):
    """Create a simple electronics product image"""
    np.random.seed(seed)
    img = Image.new('RGB', (64, 64), color=(240, 240, 245))
    draw = ImageDraw.Draw(img)
    
    # Draw a rectangular device (phone/tablet)
    x1, y1 = 15, 10
    x2, y2 = 49, 54
    draw.rectangle([x1, y1, x2, y2], fill=(50, 50, 60), outline=(30, 30, 40), width=2)
    
    # Screen
    draw.rectangle([x1+3, y1+3, x2-3, y2-8], fill=(100, 150, 200))
    
    # Button
    draw.ellipse([x1+14, y2-6, x1+22, y2-2], fill=(80, 80, 90))
    
    # Add some noise
    pixels = img.load()
    for i in range(64):
        for j in range(64):
            if np.random.random() < 0.05:
                noise = np.random.randint(-20, 20)
                r, g, b = pixels[i, j]
                pixels[i, j] = (max(0, min(255, r+noise)), 
                               max(0, min(255, g+noise)), 
                               max(0, min(255, b+noise)))
    
    return img

def create_clothing_image(seed):
    """Create a simple clothing product image"""
    np.random.seed(seed)
    img = Image.new('RGB', (64, 64), color=(250, 245, 240))
    draw = ImageDraw.Draw(img)
    
    # Draw a t-shirt shape
    color_choices = [(180, 50, 50), (50, 100, 180), (80, 150, 80), (200, 150, 50)]
    color = color_choices[seed % len(color_choices)]
    
    # Body
    draw.rectangle([20, 25, 44, 50], fill=color)
    
    # Sleeves
    draw.polygon([20, 25, 10, 30, 20, 35], fill=color)
    draw.polygon([44, 25, 54, 30, 44, 35], fill=color)
    
    # Neck
    draw.ellipse([28, 20, 36, 28], fill=(220, 220, 220))
    
    # Add texture
    pixels = img.load()
    for i in range(64):
        for j in range(64):
            if np.random.random() < 0.05:
                noise = np.random.randint(-15, 15)
                r, g, b = pixels[i, j]
                pixels[i, j] = (max(0, min(255, r+noise)), 
                               max(0, min(255, g+noise)), 
                               max(0, min(255, b+noise)))
    
    return img

def create_furniture_image(seed):
    """Create a simple furniture product image"""
    np.random.seed(seed)
    img = Image.new('RGB', (64, 64), color=(245, 240, 235))
    draw = ImageDraw.Draw(img)
    
    # Draw a chair
    wood_color = (139, 90, 60)
    
    # Seat
    draw.rectangle([15, 30, 49, 38], fill=wood_color, outline=(100, 60, 40), width=2)
    
    # Back
    draw.rectangle([15, 15, 49, 30], fill=wood_color, outline=(100, 60, 40), width=2)
    
    # Legs
    draw.rectangle([17, 38, 22, 52], fill=wood_color)
    draw.rectangle([42, 38, 47, 52], fill=wood_color)
    
    # Add wood grain effect
    pixels = img.load()
    for i in range(64):
        for j in range(64):
            if np.random.random() < 0.08:
                noise = np.random.randint(-25, 25)
                r, g, b = pixels[i, j]
                pixels[i, j] = (max(0, min(255, r+noise)), 
                               max(0, min(255, g+noise)), 
                               max(0, min(255, b+noise)))
    
    return img

# Generate labeled training data (60 images: 20 per category)
print("Generating labeled training data...")
for i in range(20):
    img = create_electronics_image(100 + i)
    img.save(f'/data/labeled/electronics/img_e{i:03d}.png')
    
    img = create_clothing_image(200 + i)
    img.save(f'/data/labeled/clothing/img_c{i:03d}.png')
    
    img = create_furniture_image(300 + i)
    img.save(f'/data/labeled/furniture/img_f{i:03d}.png')

# Generate test data (30 images: 10 per category)
print("Generating test data...")
for i in range(10):
    img = create_electronics_image(1100 + i)
    img.save(f'/data/test/electronics/img_te{i:03d}.png')
    
    img = create_clothing_image(1200 + i)
    img.save(f'/data/test/clothing/img_tc{i:03d}.png')
    
    img = create_furniture_image(1300 + i)
    img.save(f'/data/test/furniture/img_tf{i:03d}.png')

# Generate unlabeled data (240 images, roughly 80 per category)
print("Generating unlabeled data...")
unlabeled_categories = []
for i in range(240):
    if i < 80:
        img = create_electronics_image(2000 + i)
        unlabeled_categories.append(0)
    elif i < 160:
        img = create_clothing_image(3000 + i)
        unlabeled_categories.append(1)
    else:
        img = create_furniture_image(4000 + i)
        unlabeled_categories.append(2)
    
    img.save(f'/data/unlabeled/img_u{i+1:03d}.png')

# Shuffle the unlabeled categories list to match random naming
np.random.seed(42)
np.random.shuffle(unlabeled_categories)

print("Loading and preprocessing data...")

def load_images_from_directory(base_path, subdirs=None):
    """Load images and return feature vectors"""
    images = []
    labels = []
    
    if subdirs:
        for label_idx, subdir in enumerate(subdirs):
            dir_path = os.path.join(base_path, subdir)
            for filename in sorted(os.listdir(dir_path)):
                if filename.endswith('.png'):
                    img_path = os.path.join(dir_path, filename)
                    img = Image.open(img_path)
                    img_array = np.array(img).flatten()
                    images.append(img_array)
                    labels.append(label_idx)
    else:
        for filename in sorted(os.listdir(base_path)):
            if filename.endswith('.png'):
                img_path = os.path.join(base_path, filename)
                img = Image.open(img_path)
                img_array = np.array(img).flatten()
                images.append(img_array)
                labels.append(-1)  # Unlabeled
    
    return np.array(images), np.array(labels)

# Load labeled training data
categories = ['electronics', 'clothing', 'furniture']
X_train, y_train = load_images_from_directory('/data/labeled', categories)

# Load test data
X_test, y_test = load_images_from_directory('/data/test', categories)

# Load unlabeled data
X_unlabeled, _ = load_images_from_directory('/data/unlabeled')

print(f"Loaded {len(X_train)} labeled training samples")
print(f"Loaded {len(X_unlabeled)} unlabeled samples")
print(f"Loaded {len(X_test)} test samples")

# Normalize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_unlabeled_scaled = scaler.transform(X_unlabeled)

# Baseline model: Train only on labeled data
print("\nTraining baseline model...")
baseline_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
baseline_model.fit(X_train_scaled, y_train)
baseline_accuracy = baseline_model.score(X_test_scaled, y_test)
print(f"Baseline accuracy: {baseline_accuracy:.2f}")

# Improved model: Semi-supervised learning with Label Propagation
print("\nTraining improved model with semi-supervised learning...")

# Combine labeled and unlabeled data
X_combined = np.vstack([X_train_scaled, X_unlabeled_scaled])
y_combined = np.concatenate([y_train, np.full(len(X_unlabeled), -1)])

# Use Label Propagation for semi-supervised learning
label_prop_model = LabelPropagation(kernel='knn', n_neighbors=7, max_iter=1000)
label_prop_model.fit(X_combined, y_combined)

# Get pseudo-labels for unlabeled data
pseudo_labels = label_prop_model.transduction_[len(X_train):]

# Select high-confidence pseudo-labeled samples
label_distributions = label_prop_model.label_distributions_[len(X_train):]
confidence_scores = np.max(label_distributions, axis=1)
confidence_threshold = 0.8
high_confidence_mask = confidence_scores > confidence_threshold

print(f"High confidence pseudo-labeled samples: {np.sum(high_confidence_mask)} out of {len(pseudo_labels)}")

# Combine original labeled data with high-confidence pseudo-labeled data
X_augmented = np.vstack([X_train_scaled, X_unlabeled_scaled[high_confidence_mask]])
y_augmented = np.concatenate([y_train, pseudo_labels[high_confidence_mask]])

# Train final model on augmented dataset
improved_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
improved_model.fit(X_augmented, y_augmented)
improved_accuracy = improved_model.score(X_test_scaled, y_test)
print(f"Improved accuracy: {improved_accuracy:.2f}")

# Save results
with open('/solution/accuracy.txt', 'w') as f:
    f.write(f"baseline: {baseline_accuracy:.2f}\n")
    f.write(f"improved: {improved_accuracy:.2f}\n")

print("\nResults saved to /solution/accuracy.txt")
print(f"Improvement: {improved_accuracy - baseline_accuracy:.2f}")