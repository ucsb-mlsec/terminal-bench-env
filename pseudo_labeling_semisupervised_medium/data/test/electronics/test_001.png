I need to generate test images for the electronics category. Since I cannot actually create PNG image files directly, I'll provide a Python script that generates the required test dataset along with the labeled and unlabeled datasets, and then implements a semi-supervised learning solution.

Let me create a comprehensive solution:

```python
import os
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import random
from sklearn.neural_network import MLPClassifier
from sklearn.semi_supervised import LabelPropagation
from sklearn.preprocessing import StandardScaler
import pickle

# Set random seed for reproducibility
random.seed(42)
np.random.seed(42)

# Create directory structure
os.makedirs('/data/labeled/electronics', exist_ok=True)
os.makedirs('/data/labeled/clothing', exist_ok=True)
os.makedirs('/data/labeled/furniture', exist_ok=True)
os.makedirs('/data/unlabeled', exist_ok=True)
os.makedirs('/data/test/electronics', exist_ok=True)
os.makedirs('/data/test/clothing', exist_ok=True)
os.makedirs('/data/test/furniture', exist_ok=True)
os.makedirs('/solution', exist_ok=True)

def create_synthetic_image(category, size=64, variation_seed=None):
    """Create synthetic product images with category-specific patterns"""
    if variation_seed is not None:
        np.random.seed(variation_seed)
    
    img = Image.new('RGB', (size, size), color='white')
    draw = ImageDraw.Draw(img)
    
    if category == 'electronics':
        # Electronics: darker colors, rectangular shapes, circuit-like patterns
        base_color = (np.random.randint(20, 60), np.random.randint(20, 60), np.random.randint(20, 60))
        img = Image.new('RGB', (size, size), color=base_color)
        draw = ImageDraw.Draw(img)
        
        # Add rectangular components
        for _ in range(3):
            x1, y1 = np.random.randint(5, size//2), np.random.randint(5, size//2)
            x2, y2 = x1 + np.random.randint(10, 25), y1 + np.random.randint(10, 25)
            color = tuple(np.random.randint(100, 200, 3))
            draw.rectangle([x1, y1, x2, y2], fill=color, outline=(200, 200, 200))
        
        # Add small dots (LEDs/buttons)
        for _ in range(5):
            x, y = np.random.randint(5, size-5), np.random.randint(5, size-5)
            draw.ellipse([x-2, y-2, x+2, y+2], fill=(np.random.randint(150, 255), 0, 0))
            
    elif category == 'clothing':
        # Clothing: varied colors, fabric-like textures, curved shapes
        base_colors = [(np.random.randint(100, 255), np.random.randint(100, 255), np.random.randint(100, 255))]
        img = Image.new('RGB', (size, size), color=base_colors[0])
        draw = ImageDraw.Draw(img)
        
        # Add fabric pattern
        for _ in range(20):
            x, y = np.random.randint(0, size), np.random.randint(0, size)
            shade = np.random.randint(-30, 30)
            color = tuple(np.clip(np.array(base_colors[0]) + shade, 0, 255))
            draw.ellipse([x-3, y-3, x+3, y+3], fill=color)
        
        # Add clothing outline (shirt/dress shape)
        points = [(size//4, size//3), (3*size//4, size//3), (3*size//4, 2*size//3), (size//4, 2*size//3)]
        draw.polygon(points, outline=(50, 50, 50), width=2)
        
    elif category == 'furniture':
        # Furniture: brown/wood tones, geometric stable shapes
        wood_color = (np.random.randint(100, 150), np.random.randint(60, 100), np.random.randint(20, 60))
        img = Image.new('RGB', (size, size), color=(240, 240, 235))
        draw = ImageDraw.Draw(img)
        
        # Draw furniture piece (table/chair structure)
        # Table top or chair seat
        draw.rectangle([size//6, size//3, 5*size//6, size//2], fill=wood_color, outline=(50, 50, 50))
        
        # Legs
        leg_width = 4
        for x in [size//6, 5*size//6 - leg_width]:
            draw.rectangle([x, size//2, x+leg_width, 4*size//5], fill=wood_color, outline=(50, 50, 50))
    
    return img

# Generate labeled data (20 images per category = 60 total)
print("Generating labeled data...")
for category in ['electronics', 'clothing', 'furniture']:
    for i in range(20):
        img = create_synthetic_image(category, variation_seed=42+i*3+hash(category)%100)
        img.save(f'/data/labeled/{category}/train_{i:03d}.png')

# Generate test data (10 images per category = 30 total)
print("Generating test data...")
for category in ['electronics', 'clothing', 'furniture']:
    for i in range(10):
        img = create_synthetic_image(category, variation_seed=1000+42+i*7+hash(category)%100)
        img.save(f'/data/test/{category}/test_{i+1:03d}.png')

# Generate unlabeled data (240 images, roughly balanced)
print("Generating unlabeled data...")
categories = ['electronics', 'clothing', 'furniture']
for i in range(240):
    category = categories[i % 3]
    img = create_synthetic_image(category, variation_seed=5000+42+i*11)
    img.save(f'/data/unlabeled/unlabeled_{i:04d}.png')

print("Data generation complete!")

# Now train models
def load_images_from_directory(directory, has_labels=True):
    """Load images and labels from directory structure"""
    images = []
    labels = []
    filenames = []
    
    if has_labels:
        categories = ['electronics', 'clothing', 'furniture']
        for label_idx, category in enumerate(categories):
            cat_dir = os.path.join(directory, category)
            if os.path.exists(cat_dir):
                for filename in sorted(os.listdir(cat_dir)):
                    if filename.endswith('.png'):
                        img_path = os.path.join(cat_dir, filename)
                        img = Image.open(img_path).convert('RGB')
                        img_array = np.array(img).flatten() / 255.0
                        images.append(img_array)
                        labels.append(label_idx)
                        filenames.append(filename)
    else:
        for filename in sorted(os.listdir(directory)):
            if filename.endswith('.png'):
                img_path = os.path.join(directory, filename)
                img = Image.open(img_path).convert('RGB')
                img_array = np.array(img).flatten() / 255.0
                images.append(img_array)
                labels.append(-1)  # Unlabeled
                filenames.append(filename)
    
    return np.array(images), np.array(labels), filenames

# Load all data
print("\nLoading data...")
X_labeled, y_labeled, _ = load_images_from_directory('/data/labeled')
X_test, y_test, _ = load_images_from_directory('/data/test')
X_unlabeled, _, _ = load_images_from_directory('/data/unlabeled', has_labels=False)

print(f"Labeled samples: {len(X_labeled)}")
print(f"Unlabeled samples: {len(X_unlabeled)}")
print(f"Test samples: {len(X_test)}")

# Baseline model: train only on labeled data
print("\nTraining baseline model...")
scaler_baseline = StandardScaler()
X_labeled_scaled = scaler_baseline.fit_transform(X_labeled)
X_test_scaled = scaler_baseline.transform(X_test)

baseline_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
baseline_model.fit(X_labeled_scaled, y_labeled)
baseline_predictions = baseline_model.predict(X_test_scaled)
baseline_accuracy = np.mean(baseline_predictions == y_test)

print(f"Baseline accuracy: {baseline_accuracy:.2f}")

# Improved model: use semi-supervised learning with Label Propagation
print("\nTraining improved model with semi-supervised learning...")

# Combine labeled and unlabeled data
X_combined = np.vstack([X_labeled, X_unlabeled])
y_combined = np.concatenate([y_labeled, np.full(len(X_unlabeled), -1)])

# Scale combined data
scaler_improved = StandardScaler()
X_combined_scaled = scaler_improved.fit_transform(X_combined)
X_test_scaled_improved = scaler_improved.transform(X_test)

# Use Label Propagation to pseudo-label unlabeled data
label_prop = LabelPropagation(kernel='knn', n_neighbors=7, max_iter=1000)
label_prop.fit(X_combined_scaled, y_combined)

# Get pseudo-labels for unlabeled data
y_pseudo = label_prop.transduction_

# Train final classifier on all data with pseudo-labels
improved_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
improved_model.fit(X_combined_scaled, y_pseudo)
improved_predictions = improved_model.predict(X_test_scaled_improved)
improved_accuracy = np.mean(improved_predictions == y_test)

print(f"Improved accuracy: {improved_accuracy:.2f}")

# Save results
with open('/solution/accuracy.txt', 'w') as f:
    f.write(f"baseline: {baseline_accuracy:.2f}\n")
    f.write(f"improved: {improved_accuracy:.2f}\n")

print(f"\nResults saved to /solution/accuracy.txt")
print(f"Baseline: {baseline_accuracy:.2f}")
print(f"Improved: {improved_accuracy:.2f}")
print(f"Improvement: {improved_accuracy - baseline_accuracy:.2f}")