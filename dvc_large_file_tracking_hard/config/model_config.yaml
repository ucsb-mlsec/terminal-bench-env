# Machine Learning Model Configuration
# Configuration file for training and deployment settings

# Model architecture and hyperparameters
model_params:
  algorithm: RandomForestClassifier
  n_estimators: 100
  max_depth: 10
  min_samples_split: 5
  min_samples_leaf: 2
  max_features: auto
  random_state: 42
  n_jobs: -1
  verbose: 1
  class_weight: balanced
  bootstrap: true
  oob_score: true
  criterion: gini
  max_leaf_nodes: null
  min_impurity_decrease: 0.0
  warm_start: false

# Training configuration
training:
  batch_size: 32
  epochs: 50
  learning_rate: 0.001
  validation_split: 0.2
  early_stopping_patience: 10
  early_stopping_monitor: val_loss
  early_stopping_mode: min
  shuffle: true
  stratify: true
  cross_validation_folds: 5
  test_size: 0.2
  save_best_only: true
  save_weights_only: false
  model_checkpoint_monitor: val_accuracy
  reduce_lr_on_plateau: true
  reduce_lr_patience: 5
  reduce_lr_factor: 0.5
  min_learning_rate: 0.00001

# Feature configuration
features:
  categorical:
    - preferred_category
    - preferred_payment
    - customer_segment
    - region
    - subscription_type
    - device_type
    - marketing_channel
    - membership_tier
  numerical:
    - recency_days
    - frequency_score
    - monetary_score
    - avg_basket_size
    - total_transactions
    - days_since_registration
    - lifetime_value
    - discount_usage_rate
    - return_rate
    - customer_age
    - session_duration_avg
    - pages_per_visit
  target:
    - churn_label
  feature_importance_threshold: 0.01
  feature_selection_method: recursive_feature_elimination
  max_features_to_select: 20

# Data preprocessing settings
preprocessing:
  scaling: StandardScaler
  encoding: OneHotEncoder
  missing_value_strategy: mean
  outlier_detection: IQR
  outlier_threshold: 1.5
  text_vectorization: TfidfVectorizer
  date_features_extraction: true
  polynomial_features: false
  polynomial_degree: 2
  feature_interaction: false
  binning_strategy: quantile
  n_bins: 5
  handle_imbalance: SMOTE
  sampling_strategy: auto
  normalize_data: true
  remove_duplicates: true
  remove_constant_features: true
  remove_correlated_features: true
  correlation_threshold: 0.95

# File paths and directories
paths:
  data_dir: ./data
  model_dir: ./models
  output_dir: ./output
  logs_dir: ./logs
  checkpoint_dir: ./checkpoints
  plots_dir: ./plots
  reports_dir: ./reports
  temp_dir: ./temp
  cache_dir: ./cache

# Logging and monitoring
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_to_file: true
  log_file: model_training.log
  log_rotation: daily
  max_log_size_mb: 100
  backup_count: 7

# Model evaluation metrics
evaluation:
  primary_metric: accuracy
  additional_metrics:
    - precision
    - recall
    - f1_score
    - roc_auc
    - confusion_matrix
    - classification_report
  threshold_tuning: true
  optimal_threshold_metric: f1_score
  generate_plots: true
  plot_types:
    - confusion_matrix
    - roc_curve
    - precision_recall_curve
    - feature_importance
    - learning_curves

# Deployment settings
deployment:
  model_format: pickle
  model_versioning: true
  model_registry: mlflow
  serving_framework: flask
  api_port: 5000
  max_batch_size: 1000
  timeout_seconds: 30
  enable_monitoring: true
  logging_level: INFO

# Experiment tracking
experiment:
  tracking_uri: ./mlruns
  experiment_name: customer_churn_prediction
  run_name_prefix: run_
  auto_log: true
  log_artifacts: true
  log_params: true
  log_metrics: true
  tags:
    project: customer_analytics
    team: data_science
    environment: production