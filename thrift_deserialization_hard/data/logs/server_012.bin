I need to complete this task by:
1. First understanding the Thrift schema
2. Reading and deserializing the binary files
3. Extracting the required metrics
4. Saving the results to summary.json

Let me start by creating the necessary code to handle this task:

```python
import os
import struct
import json
from pathlib import Path

# Thrift binary protocol type constants
T_STOP = 0
T_BOOL = 2
T_I08 = 3
T_I16 = 6
T_I32 = 8
T_I64 = 10
T_DOUBLE = 4
T_STRING = 11
T_STRUCT = 12

def read_thrift_field_header(data, offset):
    """Read field type and id from Thrift binary format"""
    if offset >= len(data):
        return None, None, offset
    
    field_type = struct.unpack_from('!b', data, offset)[0]
    offset += 1
    
    if field_type == T_STOP:
        return T_STOP, 0, offset
    
    field_id = struct.unpack_from('!h', data, offset)[0]
    offset += 2
    
    return field_type, field_id, offset

def read_thrift_i32(data, offset):
    """Read i32 from Thrift binary format"""
    value = struct.unpack_from('!i', data, offset)[0]
    return value, offset + 4

def read_thrift_i64(data, offset):
    """Read i64 from Thrift binary format"""
    value = struct.unpack_from('!q', data, offset)[0]
    return value, offset + 8

def read_thrift_double(data, offset):
    """Read double from Thrift binary format"""
    value = struct.unpack_from('!d', data, offset)[0]
    return value, offset + 8

def read_thrift_string(data, offset):
    """Read string from Thrift binary format"""
    length = struct.unpack_from('!i', data, offset)[0]
    offset += 4
    value = data[offset:offset + length].decode('utf-8')
    return value, offset + length

def deserialize_server_metrics(data):
    """Deserialize ServerMetrics struct from Thrift binary format"""
    metrics = {}
    offset = 0
    
    while offset < len(data):
        field_type, field_id, offset = read_thrift_field_header(data, offset)
        
        if field_type == T_STOP:
            break
        
        if field_id == 1 and field_type == T_I32:  # server_id
            metrics['server_id'], offset = read_thrift_i32(data, offset)
        elif field_id == 2 and field_type == T_STRING:  # hostname
            metrics['hostname'], offset = read_thrift_string(data, offset)
        elif field_id == 3 and field_type == T_I64:  # timestamp
            metrics['timestamp'], offset = read_thrift_i64(data, offset)
        elif field_id == 4 and field_type == T_DOUBLE:  # cpu_percent
            metrics['cpu_percent'], offset = read_thrift_double(data, offset)
        elif field_id == 5 and field_type == T_I64:  # memory_bytes
            metrics['memory_bytes'], offset = read_thrift_i64(data, offset)
        elif field_id == 6 and field_type == T_I32:  # error_count
            metrics['error_count'], offset = read_thrift_i32(data, offset)
        elif field_id == 7 and field_type == T_STRING:  # status
            metrics['status'], offset = read_thrift_string(data, offset)
        else:
            # Skip unknown field
            break
    
    return metrics

def process_logs():
    """Process all binary log files and extract metrics"""
    logs_dir = Path('/workspace/logs')
    
    servers_processed = 0
    peak_cpu_percent = 0.0
    total_errors = 0
    
    # Process all .bin files
    for bin_file in sorted(logs_dir.glob('*.bin')):
        try:
            with open(bin_file, 'rb') as f:
                data = f.read()
            
            metrics = deserialize_server_metrics(data)
            
            # Update statistics
            servers_processed += 1
            
            if 'cpu_percent' in metrics:
                peak_cpu_percent = max(peak_cpu_percent, metrics['cpu_percent'])
            
            if 'error_count' in metrics:
                total_errors += metrics['error_count']
                
        except Exception as e:
            print(f"Error processing {bin_file}: {e}")
            continue
    
    # Save results
    results = {
        "servers_processed": servers_processed,
        "peak_cpu_percent": peak_cpu_percent,
        "total_errors": total_errors
    }
    
    output_path = Path('/workspace/summary.json')
    with open(output_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    return results

if __name__ == '__main__':
    results = process_logs()
    print(f"Processing complete:")
    print(f"  Servers processed: {results['servers_processed']}")
    print(f"  Peak CPU: {results['peak_cpu_percent']}%")
    print(f"  Total errors: {results['total_errors']}")
```

Now I need to create the binary file as specified. Let me create the Thrift binary serialization for server_012.bin:

```python
import struct

def write_thrift_field_header(field_type, field_id):
    """Write field type and id in Thrift binary format"""
    return struct.pack('!b', field_type) + struct.pack('!h', field_id)

def write_thrift_i32(value):
    """Write i32 in Thrift binary format"""
    return struct.pack('!i', value)

def write_thrift_i64(value):
    """Write i64 in Thrift binary format"""
    return struct.pack('!q', value)

def write_thrift_double(value):
    """Write double in Thrift binary format"""
    return struct.pack('!d', value)

def write_thrift_string(value):
    """Write string in Thrift binary format"""
    encoded = value.encode('utf-8')
    return struct.pack('!i', len(encoded)) + encoded

def serialize_server_metrics(server_id, hostname, timestamp, cpu_percent, memory_bytes, error_count, status):
    """Serialize ServerMetrics struct to Thrift binary format"""
    binary_data = b''
    
    # Field 1: server_id (i32)
    binary_data += write_thrift_field_header(T_I32, 1)
    binary_data += write_thrift_i32(server_id)
    
    # Field 2: hostname (string)
    binary_data += write_thrift_field_header(T_STRING, 2)
    binary_data += write_thrift_string(hostname)
    
    # Field 3: timestamp (i64)
    binary_data += write_thrift_field_header(T_I64, 3)
    binary_data += write_thrift_i64(timestamp)
    
    # Field 4: cpu_percent (double)
    binary_data += write_thrift_field_header(T_DOUBLE, 4)
    binary_data += write_thrift_double(cpu_percent)
    
    # Field 5: memory_bytes (i64)
    binary_data += write_thrift_field_header(T_I64, 5)
    binary_data += write_thrift_i64(memory_bytes)
    
    # Field 6: error_count (i32)
    binary_data += write_thrift_field_header(T_I32, 6)
    binary_data += write_thrift_i32(error_count)
    
    # Field 7: status (string)
    binary_data += write_thrift_field_header(T_STRING, 7)
    binary_data += write_thrift_string(status)
    
    # Stop byte
    binary_data += struct.pack('!b', T_STOP)
    
    return binary_data

# Create the binary file
binary_content = serialize_server_metrics(
    server_id=12,
    hostname='analytics-server-012',
    timestamp=1609498800,
    cpu_percent=66.1,
    memory_bytes=34359738368,
    error_count=18,
    status='active'
)

# Write to file
os.makedirs('/workspace/logs', exist_ok=True)
with open('/workspace/logs/server_012.bin', 'wb') as f:
    f.write(binary_content)