# Customer Deduplication Script

import csv
import os
from datetime import datetime
from Levenshtein import distance as levenshtein_distance

def load_customers(filepath):
    """Load customer data from CSV file."""
    customers = []
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            customers.append({
                'customer_id': int(row['customer_id']),
                'full_name': row['full_name'],
                'email': row['email'],
                'phone': row['phone'],
                'registration_date': row['registration_date']
            })
    return customers

def normalize_string(s):
    """Normalize string for comparison by converting to lowercase and removing extra spaces."""
    return s.lower().strip()

def calculate_combined_distance(customer1, customer2):
    """Calculate combined edit distance for name and email."""
    name1 = normalize_string(customer1['full_name'])
    name2 = normalize_string(customer2['full_name'])
    email1 = normalize_string(customer1['email'])
    email2 = normalize_string(customer2['email'])
    
    name_distance = levenshtein_distance(name1, name2)
    email_distance = levenshtein_distance(email1, email2)
    
    return name_distance + email_distance

def are_duplicates(customer1, customer2):
    """Determine if two customers are duplicates based on similarity threshold."""
    combined_distance = calculate_combined_distance(customer1, customer2)
    return combined_distance <= 4

def should_keep_customer1(customer1, customer2):
    """Determine which customer to keep. Returns True if customer1 should be kept."""
    date1 = datetime.strptime(customer1['registration_date'], '%Y-%m-%d')
    date2 = datetime.strptime(customer2['registration_date'], '%Y-%m-%d')
    
    if date1 < date2:
        return True
    elif date1 > date2:
        return False
    else:
        # Dates are equal, use customer_id as tiebreaker
        return customer1['customer_id'] < customer2['customer_id']

def find_duplicates(customers):
    """Find all duplicate groups using optimized comparison."""
    n = len(customers)
    to_remove = set()
    
    # Compare each pair of customers
    for i in range(n):
        if customers[i]['customer_id'] in to_remove:
            continue
            
        for j in range(i + 1, n):
            if customers[j]['customer_id'] in to_remove:
                continue
                
            if are_duplicates(customers[i], customers[j]):
                # Determine which one to remove
                if should_keep_customer1(customers[i], customers[j]):
                    to_remove.add(customers[j]['customer_id'])
                else:
                    to_remove.add(customers[i]['customer_id'])
                    break  # Customer i is being removed, no need to continue comparing
    
    return to_remove

def deduplicate_customers(input_filepath, output_filepath):
    """Main deduplication function."""
    # Load customers
    print("Loading customer data...")
    customers = load_customers(input_filepath)
    print(f"Loaded {len(customers)} customers")
    
    # Find duplicates
    print("Finding duplicates...")
    ids_to_remove = find_duplicates(customers)
    print(f"Found {len(ids_to_remove)} duplicate records to remove")
    
    # Filter out duplicates
    deduplicated = [c for c in customers if c['customer_id'] not in ids_to_remove]
    
    # Sort by customer_id
    deduplicated.sort(key=lambda x: x['customer_id'])
    
    # Write output
    print(f"Writing {len(deduplicated)} records to output...")
    os.makedirs(os.path.dirname(output_filepath), exist_ok=True)
    
    with open(output_filepath, 'w', encoding='utf-8', newline='') as f:
        fieldnames = ['customer_id', 'full_name', 'email', 'phone', 'registration_date']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(deduplicated)
    
    print(f"Deduplication complete. Output saved to {output_filepath}")
    return len(deduplicated)

def validate_known_duplicates(output_filepath, known_duplicates_filepath):
    """Validate that known duplicates are handled correctly."""
    # Load output customer IDs
    output_ids = set()
    with open(output_filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            output_ids.add(int(row['customer_id']))
    
    # Check known duplicates
    print("\nValidating known duplicates...")
    with open(known_duplicates_filepath, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            id1, id2 = map(int, line.strip().split(','))
            in_output = [id1 in output_ids, id2 in output_ids]
            
            if sum(in_output) == 1:
                print(f"✓ Pair {id1},{id2}: Correctly kept one record")
            elif sum(in_output) == 0:
                print(f"✗ Pair {id1},{id2}: ERROR - Both records removed")
            else:
                print(f"✗ Pair {id1},{id2}: ERROR - Both records kept")

if __name__ == "__main__":
    input_file = "/data/customers.csv"
    output_file = "/output/deduplicated.csv"
    known_duplicates_file = "/data/known_duplicates.txt"
    
    start_time = datetime.now()
    
    # Run deduplication
    num_output = deduplicate_customers(input_file, output_file)
    
    # Validate results
    if os.path.exists(known_duplicates_file):
        validate_known_duplicates(output_file, known_duplicates_file)
    
    elapsed = (datetime.now() - start_time).total_seconds()
    print(f"\nTotal processing time: {elapsed:.2f} seconds")
    print(f"Output records: {num_output}")